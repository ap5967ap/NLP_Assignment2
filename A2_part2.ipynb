{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Python Imports for Deep Learning and NLP Task\n",
    "\n",
    "##### **Deep Learning (Keras)**\n",
    "- `Sequential` - Used to build a sequential model.\n",
    "- `Dense` - Fully connected layer for neural networks.\n",
    "- `Dropout` - Regularization technique to prevent overfitting.\n",
    "- `BatchNormalization` - Normalizes activations to stabilize training.\n",
    "- `ReLU` - Activation function for non-linearity.\n",
    "- `Adam`, `SGD` - Optimizers for training the model.\n",
    "\n",
    "##### **Data Handling (Pandas & NumPy)**\n",
    "- `pandas` (`pd`) - Data manipulation and analysis.\n",
    "- `numpy` (`np`) - Array processing and numerical computations.\n",
    "\n",
    "##### **Natural Language Processing (NLTK & Emoji)**\n",
    "- `nltk` - Natural language toolkit for text processing.\n",
    "- `WordNetLemmatizer` - Lemmatization to normalize words.\n",
    "- `emoji` - Handles emojis in text data.\n",
    "\n",
    "##### **Feature Engineering (Scikit-learn)**\n",
    "- `TfidfVectorizer` - Converts text into TF-IDF features.\n",
    "- `train_test_split` - Splits dataset into training and testing sets.\n",
    "- `resample` - Used for data resampling (e.g., handling imbalanced data).\n",
    "\n",
    "##### **Text Cleaning & Regular Expressions**\n",
    "- `re` - Regular expressions for text processing.\n",
    "- `string` - String manipulations.\n",
    "\n",
    "##### **Performance Evaluation (Scikit-learn)**\n",
    "- `accuracy_score` - Computes classification accuracy.\n",
    "- `confusion_matrix` - Evaluates model performance with a confusion matrix.\n",
    "\n",
    "##### **Data Visualization (Matplotlib & Seaborn)**\n",
    "- `matplotlib.pyplot` (`plt`) - Creates plots and figures.\n",
    "- `seaborn` (`sns`) - Statistical data visualization.\n",
    "\n",
    "##### **Categorical Data Handling (Keras)**\n",
    "- `to_categorical` - Converts labels to one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 23:12:34.998503: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-17 23:12:35.036225: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization,ReLU\n",
    "from keras.optimizers import Adam,SGD\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import emoji\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "import string\n",
    "from keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading and Importing essential NLP Packages\n",
    "\n",
    "- **stopwords** - Words that are commonly used in the English language.\n",
    "- **punkt** - A tokenizer model for splitting text into words or sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ap/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ap/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Visualizing the Data\n",
    "\n",
    "We have used on `Text` and `Sentiment` columns for our analysis. The `Sentiment` column is our target variable, and the `Text` column is our feature variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./sentimentdataset.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Enjoying a beautiful day at the park!        ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 12:30:00</td>\n",
       "      <td>User123</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Nature #Park</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Traffic was terrible this morning.           ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2023-01-15 08:45:00</td>\n",
       "      <td>CommuterX</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Traffic #Morning</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Just finished an amazing workout! 💪          ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 15:45:00</td>\n",
       "      <td>FitnessFan</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Fitness #Workout</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Excited about the upcoming weekend getaway!  ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 18:20:00</td>\n",
       "      <td>AdventureX</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>#Travel #Adventure</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Trying out a new recipe for dinner tonight.  ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2023-01-15 19:55:00</td>\n",
       "      <td>ChefCook</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Cooking #Food</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  \\\n",
       "0             0           0   \n",
       "1             1           1   \n",
       "2             2           2   \n",
       "3             3           3   \n",
       "4             4           4   \n",
       "\n",
       "                                                Text    Sentiment  \\\n",
       "0   Enjoying a beautiful day at the park!        ...   Positive     \n",
       "1   Traffic was terrible this morning.           ...   Negative     \n",
       "2   Just finished an amazing workout! 💪          ...   Positive     \n",
       "3   Excited about the upcoming weekend getaway!  ...   Positive     \n",
       "4   Trying out a new recipe for dinner tonight.  ...   Neutral      \n",
       "\n",
       "             Timestamp            User     Platform  \\\n",
       "0  2023-01-15 12:30:00   User123          Twitter     \n",
       "1  2023-01-15 08:45:00   CommuterX        Twitter     \n",
       "2  2023-01-15 15:45:00   FitnessFan      Instagram    \n",
       "3  2023-01-15 18:20:00   AdventureX       Facebook    \n",
       "4  2023-01-15 19:55:00   ChefCook        Instagram    \n",
       "\n",
       "                                     Hashtags  Retweets  Likes       Country  \\\n",
       "0   #Nature #Park                                  15.0   30.0     USA         \n",
       "1   #Traffic #Morning                               5.0   10.0     Canada      \n",
       "2   #Fitness #Workout                              20.0   40.0   USA           \n",
       "3   #Travel #Adventure                              8.0   15.0     UK          \n",
       "4   #Cooking #Food                                 12.0   25.0    Australia    \n",
       "\n",
       "   Year  Month  Day  Hour  \n",
       "0  2023      1   15    12  \n",
       "1  2023      1   15     8  \n",
       "2  2023      1   15    15  \n",
       "3  2023      1   15    18  \n",
       "4  2023      1   15    19  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0.1    0\n",
       "Unnamed: 0      0\n",
       "Text            0\n",
       "Sentiment       0\n",
       "Timestamp       0\n",
       "User            0\n",
       "Platform        0\n",
       "Hashtags        0\n",
       "Retweets        0\n",
       "Likes           0\n",
       "Country         0\n",
       "Year            0\n",
       "Month           0\n",
       "Day             0\n",
       "Hour            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Target Variable and OverSampling \n",
    "\n",
    "The Sentiment column had a lot of spaces which were removed using the `strip()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'] = df['Sentiment'].str.strip().str.replace(r'\\s+', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OverSampling\n",
    "\n",
    "This was done to balance the dataset. The dataset was imbalanced, and the model was biased towards the majority class. We used the `resample` function from the `sklearn.utils` module to balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df['Sentiment'].value_counts()\n",
    "rare_classes = class_counts[class_counts < 2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuMAAAGHCAYAAAAa8Fx1AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAATnJJREFUeJzt3Xd8VFX+//H3TZtMSEihJISSUAICoTcBkSDFgmJERb8oxRULRQyKIrBKcBUWkKKywLoiYEHUFbDAsiBNKe4iCAgq6gqCaxClhBIIJef3B7+5m0kmIQmJN4mv5+NxHnDLKbfOJ2funGsZY4wAAAAA/Ob8nG4AAAAA8HtFMA4AAAA4hGAcAAAAcAjBOAAAAOAQgnEAAADAIQTjAAAAgEMIxgEAAACHEIwDAAAADiEYBwAAABxCMA6UUfPnz5dlWXYKDg5WTEyMunTpookTJ+rQoUO58qSmpsqyrELVk5GRodTUVK1bt65Q+XzVFR8frxtvvLFQ5VzKwoULNWPGDJ/LLMtSampqsdZX3FavXq3WrVurQoUKsixLS5cuzXPdAwcOaMiQIapfv77cbreioqLUpEkT3XfffTpw4ECJtnPWrFmaP39+rvn79u2TZVk+l5UmmzZtUmpqqo4dO1ag9T3n76+//nrZdXv20XPPPXfZZeUss7TvdwCXFuB0AwBcnnnz5umKK67QuXPndOjQIW3YsEGTJk3Sc889p7feekvdunWz1x00aJCuu+66QpWfkZGh8ePHS5KSkpIKnK8odRXFwoULtWvXLqWkpORatnnzZtWoUaPE21BUxhj16dNH9evX1/vvv68KFSqoQYMGPtf98ccf1bJlS0VEROjRRx9VgwYNlJ6eri+//FJvv/22vv/+e9WsWbPE2jpr1ixVrlxZAwcO9JpfrVo1bd68WXXr1i2xuovDpk2bNH78eA0cOFARERFONwcAbATjQBmXmJio1q1b29O33nqrRowYoauuukq9e/fWt99+q+joaElSjRo1Sjw4zcjIUEhIyG9S16VceeWVjtZ/KT/99JOOHDmiW265RV27ds133b/97W/69ddf9e9//1u1a9e25ycnJ2vMmDHKysoq6eb65HK5Sv1+BoDSjMdUgHKoVq1amjp1qk6cOKG//vWv9nxfj46sWbNGSUlJqlSpktxut2rVqqVbb71VGRkZ2rdvn6pUqSJJGj9+vP1IjKd31FPetm3bdNtttykyMtLuIc3vkZglS5aoadOmCg4OVp06dfTCCy94Lfc8grNv3z6v+evWrZNlWfYjM0lJSVq2bJl++OEHr0d2PHw9prJr1y7dfPPNioyMVHBwsJo3b64FCxb4rOfNN9/U2LFjFRsbq4oVK6pbt27as2dP3js+mw0bNqhr164KCwtTSEiIOnTooGXLltnLU1NT7T9WRo0aJcuyFB8fn2d5hw8flp+fn6pWrepzuZ+f9+38s88+U69evRQVFaXg4GC1aNFCb7/9ttc6nv28du1aDR48WJUrV1alSpXUu3dv/fTTT/Z68fHx2r17t9avX2/vY09bfT0u4Tn2O3fu1O23367w8HBFRUXpkUce0fnz57Vnzx5dd911CgsLU3x8vCZPnpxre44fP66RI0eqdu3aCgoKUvXq1ZWSkqJTp055rWdZloYNG6bXXntNDRs2VEhIiJo1a6YPP/zQqz2PPfaYJKl27dr2NhT20aucfvnlFw0ZMkSNGjVSaGioqlatqmuuuUaffPKJz/WzsrL07LPPqlatWgoODlbr1q21evXqXOt9++236tu3r6pWrSqXy6WGDRvqL3/5S4Hac//996tmzZpyuVyqUqWKOnbsqI8++uiythNAySIYB8qpG264Qf7+/vr444/zXGffvn3q2bOngoKC9Morr2jFihX685//rAoVKujs2bOqVq2aVqxYIUm69957tXnzZm3evFlPPvmkVzm9e/dWvXr19M4772jOnDn5tmv79u1KSUnRiBEjtGTJEnXo0EEPP/xwkZ6nnTVrljp27KiYmBi7bZs3b85z/T179qhDhw7avXu3XnjhBS1evFiNGjXSwIEDfQaEY8aM0Q8//KCXX35ZL730kr799lvddNNNunDhQr7tWr9+va655hqlp6dr7ty5evPNNxUWFqabbrpJb731lqSLj/EsXrxYkvTQQw9p8+bNWrJkSZ5ltm/fXllZWerdu7f++c9/6vjx43muu3btWnXs2FHHjh3TnDlz9N5776l58+a64447fD5jPGjQIAUGBmrhwoWaPHmy1q1bp7vvvttevmTJEtWpU0ctWrSw93F+bfXo06ePmjVrpnfffVf33Xefpk+frhEjRig5OVk9e/bUkiVLdM0112jUqFH2vpAufrvSuXNnLViwQMOHD9c//vEPjRo1SvPnz1evXr1kjPGqZ9myZZo5c6aefvppvfvuu4qKitItt9yi77//3t6+hx56SJK0ePFiextatmx5yW3Iz5EjRyRJ48aN07JlyzRv3jzVqVNHSUlJPgP9mTNnasWKFZoxY4Zef/11+fn56frrr/c6Z7/88ku1adNGu3bt0tSpU/Xhhx+qZ8+eGj58uP24WF769eunpUuX6qmnntLKlSv18ssvq1u3bjp8+PBlbSeAEmYAlEnz5s0zksyWLVvyXCc6Oto0bNjQnh43bpzJftn//e9/N5LM9u3b8yzjl19+MZLMuHHjci3zlPfUU0/luSy7uLg4Y1lWrvq6d+9uKlasaE6dOuW1bXv37vVab+3atUaSWbt2rT2vZ8+eJi4uzmfbc7b7zjvvNC6Xy+zfv99rveuvv96EhISYY8eOedVzww03eK339ttvG0lm8+bNPuvzuPLKK03VqlXNiRMn7Hnnz583iYmJpkaNGiYrK8sYY8zevXuNJDNlypR8yzPGmKysLPPAAw8YPz8/I8lYlmUaNmxoRowYkWs/XXHFFaZFixbm3LlzXvNvvPFGU61aNXPhwgVjzP/285AhQ7zWmzx5spFk0tLS7HmNGzc2nTt3ztUuzzbMmzfPnuc59lOnTvVat3nz5kaSWbx4sT3v3LlzpkqVKqZ37972vIkTJxo/P79c57bnfF2+fLk9T5KJjo42x48ft+cdPHjQ+Pn5mYkTJ9rzpkyZ4vOcyotnG3755ZcCrW/MxWN87tw507VrV3PLLbfY8z37KDY21pw+fdqef/z4cRMVFWW6detmz7v22mtNjRo1THp6ulfZw4YNM8HBwebIkSNeZWbf76GhoSYlJaXA7QVQOtAzDpRjJkcPYk7NmzdXUFCQ7r//fi1YsMDuSSysW2+9tcDrNm7cWM2aNfOa17dvXx0/flzbtm0rUv0FtWbNGnXt2jXXDx0HDhyojIyMXL3qvXr18ppu2rSpJOmHH37Is45Tp07pX//6l2677TaFhoba8/39/dWvXz/9+OOPBX7UJTvLsjRnzhx9//33mjVrlu655x6dO3dO06dPV+PGjbV+/XpJ0nfffaevv/5ad911lyTp/PnzdrrhhhuUlpaWq/6ibGdB5Bw5p2HDhrIsS9dff709LyAgQPXq1fOq68MPP1RiYqKaN2/u1f5rr73W5+MlXbp0UVhYmD0dHR2tqlWrXnb7C2LOnDlq2bKlgoODFRAQoMDAQK1evVpfffVVrnV79+6t4OBge9rzbcnHH3+sCxcu6MyZM1q9erVuueUWhYSE5Dp2Z86c0aeffppnW9q2bav58+frmWee0aeffqpz586VyDYDKF4E40A5derUKR0+fFixsbF5rlO3bl199NFHqlq1qoYOHaq6deuqbt26ev755wtVV7Vq1Qq8bkxMTJ7zSvrr9MOHD/tsq2cf5ay/UqVKXtMul0uSdPr06TzrOHr0qIwxhaqnMOLi4jR48GDNnTtX3377rd566y2dOXPGfib6559/liSNHDlSgYGBXmnIkCGSlGu4vqJsZ0FERUV5TQcFBSkkJMQrIPXMP3PmjD39888/a+fOnbnaHxYWJmPMJdvv2YbLbf+lTJs2TYMHD1a7du307rvv6tNPP9WWLVt03XXX+aw7r3P/7NmzOnnypA4fPqzz58/rxRdfzLXtN9xwg6Tcxy67t956SwMGDNDLL7+s9u3bKyoqSv3799fBgweLb6MBFDtGUwHKqWXLlunChQuXHI6wU6dO6tSpky5cuKDPPvtML774olJSUhQdHa0777yzQHUVZuxyX4GBZ54nqPIEa5mZmV7rXe6Yz5UqVVJaWlqu+Z4fK1auXPmyypekyMhI+fn5lXg9Hn369NHEiRO1a9cur7JHjx6t3r17+8yT1/CJpUXlypXldrv1yiuv5Lm8NHj99deVlJSk2bNne80/ceKEz/XzOveDgoIUGhqqwMBA+xuUoUOH+iwj+0g6OVWuXFkzZszQjBkztH//fr3//vt64okndOjQIfu3HwBKH4JxoBzav3+/Ro4cqfDwcD3wwAMFyuPv76927drpiiuu0BtvvKFt27bpzjvvLLZeUo/du3drx44dXo+qLFy4UGFhYfYP6jwjdezcudMrcHz//fdzlVeYHtCuXbtqyZIl+umnn7y+MXj11VcVEhJSLEP0VahQQe3atdPixYv13HPPye12S7o4ksbrr7+uGjVqqH79+oUuNy0tzWdv+8mTJ3XgwAF7exo0aKCEhATt2LFDEyZMuLyNyea36Gn2uPHGGzVhwgRVqlQp3+CzMIr7PJYu/hHqKddj586d2rx5s88x3xcvXqwpU6bYf2yeOHFCH3zwgTp16iR/f3+FhISoS5cu+vzzz9W0aVMFBQUVuW21atXSsGHDtHr1am3cuLHI5QAoeQTjQBm3a9cu+7nSQ4cO6ZNPPtG8efPk7++vJUuW2EMT+jJnzhytWbNGPXv2VK1atXTmzBm7N9LzsqCwsDDFxcXpvffeU9euXRUVFaXKlSvnOwxffmJjY9WrVy+lpqaqWrVqev3117Vq1SpNmjRJISEhkqQ2bdqoQYMGGjlypM6fP6/IyEgtWbJEGzZsyFVekyZNtHjxYs2ePVutWrWSn5+f17jr2Y0bN04ffvihunTpoqeeekpRUVF64403tGzZMk2ePFnh4eFF2qacJk6cqO7du6tLly4aOXKkgoKCNGvWLO3atUtvvvlmod+CKknPPvusNm7cqDvuuEPNmzeX2+3W3r17NXPmTB0+fFhTpkyx1/3rX/+q66+/Xtdee60GDhyo6tWr68iRI/rqq6+0bds2vfPOO4Wuv0mTJlq0aJHeeust1alTR8HBwWrSpEmhyymIlJQUvfvuu7r66qs1YsQINW3aVFlZWdq/f79WrlypRx99VO3atSt0+yXp+eef14ABAxQYGKgGDRp4PWvuywcffOBzndtuu0033nij/vSnP2ncuHHq3Lmz9uzZo6efflq1a9fW+fPnc+Xx9/dX9+7d9cgjjygrK0uTJk3S8ePHvUZJef7553XVVVepU6dOGjx4sOLj43XixAl99913+uCDD7RmzRqf7UxPT1eXLl3Ut29fXXHFFQoLC9OWLVu0YsWKPL8hAVA6EIwDZdw999wj6eJztxEREWrYsKFGjRqlQYMG5RuISxd/wLly5UqNGzdOBw8eVGhoqBITE/X++++rR48e9npz587VY489pl69eikzM1MDBgwo8mu4mzdvrnvuuUfjxo3Tt99+q9jYWE2bNk0jRoyw1/H399cHH3ygYcOG6cEHH5TL5dKdd96pmTNnqmfPnl7lPfzww9q9e7fGjBmj9PR0GWPy/OFqgwYNtGnTJo0ZM0ZDhw7V6dOn1bBhQ82bNy/XmyUvR+fOnbVmzRqNGzdOAwcOVFZWlpo1a6b3338/148aC6pfv36SpEWLFmnKlClKT09XVFSUWrVqpeXLl3v9KLJLly7697//rWeffVYpKSk6evSoKlWqpEaNGqlPnz5Fqn/8+PFKS0vTfffdpxMnTiguLi7XOPDFpUKFCvrkk0/05z//WS+99JL27t1rj4HfrVu3Iv0hmJSUpNGjR2vBggX629/+pqysLK1du/aSj3H94Q9/8DnfGKOxY8cqIyNDc+fO1eTJk9WoUSPNmTNHS5Ys8Tm04bBhw3TmzBkNHz5chw4dUuPGjbVs2TJ17NjRXqdRo0batm2b/vSnP+mPf/yjDh06pIiICCUkJNjPjfsSHBysdu3a6bXXXtO+fft07tw51apVS6NGjdLjjz9eoH0EwBmWudRwCwAAAABKBKOpAAAAAA4hGAcAAAAcQjAOAAAAOIRgHAAAAHAIwTgAAADgEIJxAAAAwCG/23HGs7Ky9NNPPyksLKxIL+AAAABAyTLG6MSJE4qNjZWfX/nsQ/7dBuM//fSTz9cVAwAAoHQ5cOCAatSo4XQzSsTvNhj3vN74wIEDqlixosOtAQAAQE7Hjx9XzZo17bitPPrdBuOeR1MqVqxIMA4AAFCKledHisvnwzcAAABAGUAwDgAAADiEYBwAAABwCME4AAAA4BCCcQAAAMAhBOMAAACAQwjGAQAAAIcQjAMAAAAOIRgHAAAAHEIwDgAAADiEYBwAAABwSIDTDQAAAOVTq8detf+/dUp/B1sClF70jAMAAAAOIRgHAAAAHEIwDgAAADiEYBwAAABwCME4AAAA4BCCcQAAAMAhBOMAgHKp1WOveg2tBwClEcE4AAAA4BCCcQAAAMAhBOMAAACAQwjGAQAAAIcQjAMAAAAOIRgHAAAAHEIwDgAAADiEYBwAAABwCME4AAAA4BCCcQAAAMAhBOMAAACAQwjGAQAAAIcQjAMAAAAOIRgHAAAAHEIwDgAAADiEYBwAAABwCME4AAAA4BCCcQAAAMAhBOMAAACAQwjGAQAAAIcQjAMAAAAOKfXB+MSJE2VZllJSUux5xhilpqYqNjZWbrdbSUlJ2r17t3ONBAAAAIqgVAfjW7Zs0UsvvaSmTZt6zZ88ebKmTZummTNnasuWLYqJiVH37t114sQJh1oKAAAAFF6pDcZPnjypu+66S3/7298UGRlpzzfGaMaMGRo7dqx69+6txMRELViwQBkZGVq4cKGDLQYAAAAKp9QG40OHDlXPnj3VrVs3r/l79+7VwYMH1aNHD3uey+VS586dtWnTpjzLy8zM1PHjx70SAAAA4KQApxvgy6JFi7Rt2zZt2bIl17KDBw9KkqKjo73mR0dH64cffsizzIkTJ2r8+PHF21AAAADgMpS6nvEDBw7o4Ycf1uuvv67g4OA817Msy2vaGJNrXnajR49Wenq6nQ4cOFBsbQYAAACKotT1jG/dulWHDh1Sq1at7HkXLlzQxx9/rJkzZ2rPnj2SLvaQV6tWzV7n0KFDuXrLs3O5XHK5XCXXcAAAAKCQSl3PeNeuXfXFF19o+/btdmrdurXuuusubd++XXXq1FFMTIxWrVpl5zl79qzWr1+vDh06ONhyAAAAoHBKXc94WFiYEhMTveZVqFBBlSpVsuenpKRowoQJSkhIUEJCgiZMmKCQkBD17dvXiSYDAAAARVLqgvGCePzxx3X69GkNGTJER48eVbt27bRy5UqFhYU53TQAAACgwMpEML5u3TqvacuylJqaqtTUVEfaAwAAABSHUvfMOAAAAPB7QTAOAAAAOIRgHAAAAHAIwTgAAADgEIJxAAAAwCEE4wAAAIBDCMYBAAAAhxCMAwAAAA4hGAcAAAAcQjAOAAAAOIRgHAAAAHAIwTgAAADgEIJxAAAAwCEE4wDKnVaPvapWj73qdDMAALgkgnEAAADAIQTjAAAAgEMIxgEAAACHEIwDAAAADiEYBwAAABxCMA4AAAA4hGAcAAAAcAjBOAAAAOAQgnEAAADAIQTjAAAAgEMIxgEAAACHEIwDAAAADiEYBwAAABxCMA4AAAA4hGAcAAAAcAjBOAAAAOAQgnEAAADAIQTjAAAAgEMIxgEAAACHEIwDAAAADiEYBwAAABxCMA4AAAA4hGAcAAAAcAjBOAAAAOAQgnEAAADAIQTjAAAAgEMIxgEAAACHEIwDAAAADiEYBwAAABxCMA4AAAA4hGAcAAAAcAjBOAAAAOAQgnEAAADAIQTjAAAAgEMIxgEAAACHEIwDAAAADiEYBwAAABxCMA4AAAA4hGAcAAAAcAjBOAAAAOCQUheMz549W02bNlXFihVVsWJFtW/fXv/4xz/s5cYYpaamKjY2Vm63W0lJSdq9e7eDLQYAAACKptQF4zVq1NCf//xnffbZZ/rss890zTXX6Oabb7YD7smTJ2vatGmaOXOmtmzZopiYGHXv3l0nTpxwuOUAAABA4ZS6YPymm27SDTfcoPr166t+/fp69tlnFRoaqk8//VTGGM2YMUNjx45V7969lZiYqAULFigjI0MLFy50uukAAABAoZS6YDy7CxcuaNGiRTp16pTat2+vvXv36uDBg+rRo4e9jsvlUufOnbVp06Z8y8rMzNTx48e9EgAAAOCkUhmMf/HFFwoNDZXL5dKDDz6oJUuWqFGjRjp48KAkKTo62mv96Ohoe1leJk6cqPDwcDvVrFmzxNoPAAAAFESpDMYbNGig7du369NPP9XgwYM1YMAAffnll/Zyy7K81jfG5JqX0+jRo5Wenm6nAwcOlEjbAQAAgIIKcLoBvgQFBalevXqSpNatW2vLli16/vnnNWrUKEnSwYMHVa1aNXv9Q4cO5eotz8nlcsnlcpVcowEAAIBCKpU94zkZY5SZmanatWsrJiZGq1atspedPXtW69evV4cOHRxsIQAAAFB4pa5nfMyYMbr++utVs2ZNnThxQosWLdK6deu0YsUKWZallJQUTZgwQQkJCUpISNCECRMUEhKivn37Ot10AAAAoFBKXTD+888/q1+/fkpLS1N4eLiaNm2qFStWqHv37pKkxx9/XKdPn9aQIUN09OhRtWvXTitXrlRYWJjDLQcAAAAKp9QF43Pnzs13uWVZSk1NVWpq6m/TIAAAAKCElIlnxgEAAIDyiGAcAAAAcAjBOAAAAOAQgnEAAADAIQTjAAAAgEMIxgEAAACHEIwDAAAADiEYBwAAABxCMA4AAAA4hGAcAAAAcAjBOAAAAOAQgnEAAADAIQTjAAAAgEMIxgEAAACHEIwDAAAADiEYBwAAABxCMA4AAAA4pNiC8Tp16ujw4cO55h87dkx16tQprmoAAACAcqPYgvF9+/bpwoULueZnZmbqv//9b3FVAwAAAJQbAZdbwPvvv2///5///KfCw8Pt6QsXLmj16tWKj4+/3GoAAACAcueyg/Hk5GRJkmVZGjBggNeywMBAxcfHa+rUqZdbDQAAAFDuXHYwnpWVJUmqXbu2tmzZosqVK192owAAAIDfg8sOxj327t1bXEUBAAAAvwvFFoxL0urVq7V69WodOnTI7jH3eOWVV4qzKgAAAKDMK7ZgfPz48Xr66afVunVrVatWTZZlFVfRAAAAQLlUbMH4nDlzNH/+fPXr16+4igQAAADKtWIbZ/zs2bPq0KFDcRUHAAAAlHvFFowPGjRICxcuLK7iAAAAgHKv2B5TOXPmjF566SV99NFHatq0qQIDA72WT5s2rbiqAgAAAMqFYgvGd+7cqebNm0uSdu3a5bWMH3MCAAAAuRVbML527driKgoAAAD4XSi2Z8YBAAAAFE6x9Yx36dIl38dR1qxZU1xVAQAAAOVCsQXjnufFPc6dO6ft27dr165dGjBgQHFVAwAAAJQbxRaMT58+3ef81NRUnTx5sriqAQAAAMqNEn9m/O6779Yrr7xS0tUAAAAAZU6JB+ObN29WcHBwSVcDAAAAlDnF9phK7969vaaNMUpLS9Nnn32mJ598sriqAQAAAMqNYgvGw8PDvab9/PzUoEEDPf300+rRo0dxVQMAAACUG8UWjM+bN6+4igIAAAB+F4otGPfYunWrvvrqK1mWpUaNGqlFixbFXQUAAABQLhRbMH7o0CHdeeedWrdunSIiImSMUXp6urp06aJFixapSpUqxVUVAAAAUC4U22gqDz30kI4fP67du3fryJEjOnr0qHbt2qXjx49r+PDhxVUNAAAAUG4UW8/4ihUr9NFHH6lhw4b2vEaNGukvf/kLP+AEAAAAfCi2nvGsrCwFBgbmmh8YGKisrKziqgYAAAAoN4otGL/mmmv08MMP66effrLn/fe//9WIESPUtWvX4qoGAAAAKDeKLRifOXOmTpw4ofj4eNWtW1f16tVT7dq1deLECb344ovFVQ0AAABQbhTbM+M1a9bUtm3btGrVKn399dcyxqhRo0bq1q1bcVUBAAAAlCuX3TO+Zs0aNWrUSMePH5ckde/eXQ899JCGDx+uNm3aqHHjxvrkk08uu6EAAABAeXPZwfiMGTN03333qWLFirmWhYeH64EHHtC0adMutxoAAACg3LnsYHzHjh267rrr8lzeo0cPbd269XKrAQAAAMqdyw7Gf/75Z59DGnoEBATol19+udxqAAAAgHLnsoPx6tWr64svvshz+c6dO1WtWrXLrQYAAAAody47GL/hhhv01FNP6cyZM7mWnT59WuPGjdONN954udUAAAAA5c5lB+N//OMfdeTIEdWvX1+TJ0/We++9p/fff1+TJk1SgwYNdOTIEY0dO7bA5U2cOFFt2rRRWFiYqlatquTkZO3Zs8drHWOMUlNTFRsbK7fbraSkJO3evftyNwUAAAD4TV12MB4dHa1NmzYpMTFRo0eP1i233KLk5GSNGTNGiYmJ2rhxo6Kjowtc3vr16zV06FB9+umnWrVqlc6fP68ePXro1KlT9jqTJ0/WtGnTNHPmTG3ZskUxMTHq3r27Tpw4cbmbAwAAAPxmiuWlP3FxcVq+fLmOHj2q7777TsYYJSQkKDIystBlrVixwmt63rx5qlq1qrZu3aqrr75axhjNmDFDY8eOVe/evSVJCxYsUHR0tBYuXKgHHnigODYJAAAAKHHF9gZOSYqMjFSbNm2Ks0ilp6dLkqKioiRJe/fu1cGDB9WjRw97HZfLpc6dO2vTpk15BuOZmZnKzMy0pz0vKQIAAACcctmPqZQkY4weeeQRXXXVVUpMTJQkHTx4UJJyPfoSHR1tL/Nl4sSJCg8Pt1PNmjVLruEAAABAAZTqYHzYsGHauXOn3nzzzVzLLMvymjbG5JqX3ejRo5Wenm6nAwcOFHt7AQAAgMIo1sdUitNDDz2k999/Xx9//LFq1Khhz4+JiZF0sYc8+/jlhw4dyveHoi6XSy6Xq+QaDAAAABRSqesZN8Zo2LBhWrx4sdasWaPatWt7La9du7ZiYmK0atUqe97Zs2e1fv16dejQ4bduLgAAAFBkpa5nfOjQoVq4cKHee+89hYWF2c+Bh4eHy+12y7IspaSkaMKECUpISFBCQoImTJigkJAQ9e3b1+HWAwAAAAVX6oLx2bNnS5KSkpK85s+bN08DBw6UJD3++OM6ffq0hgwZoqNHj6pdu3ZauXKlwsLCfuPWAgAAAEVX6oJxY8wl17EsS6mpqUpNTS35BgEAAAAlpNQF48BvrdVjr9r/3zqlv4MtAQAAvzel7gecAAAAwO8FwTgAAADgEIJxAAAAwCEE4wAAAIBDCMYBAAAAhzCaCgCUAozqg+LAeQSUPfSMAwAAAA4hGAcAAAAcQjAOAAAAOIRgHAAAAHAIwTgAAADgEIJxAAAAwCEE4wAAAIBDCMYBAAAAhxCMAwAAAA4hGAcAAAAcQjAOAAAAOIRgHAAAAHBIgNMNAMqTVo+9av9/65T+DrYEAACUBfSMAwAAAA4hGAcAAAAcQjAOAAAAOIRgHAAAAHAIwTgAAADgEIJxAAAAwCEMbQgAAFBCGPIWl0LPOAAAAOAQgnEAAADAIQTjAAAAgEMIxgEAAACHEIwDAAAADmE0FQAoQxiZAQDKF3rGAQAAAIcQjAMAAAAOIRgHAAAAHEIwDgAAADiEYBwAAABwCME4AAAA4BCCcQAAAMAhBOMAAACAQwjGAQAAAIcQjAMAAAAOIRgHAAAAHEIwDgAAADiEYBwAAABwCME4AAAA4BCCcQAAAMAhBOMAAACAQwjGAQAAAIcQjAMAAAAOIRgHAAAAHBLgdAOA37tWj71q/3/rlP4OtgRAeeO5v3BvAUovesYBAAAAhxCMAwAAAA4plcH4xx9/rJtuukmxsbGyLEtLly71Wm6MUWpqqmJjY+V2u5WUlKTdu3c701gAAACgiEplMH7q1Ck1a9ZMM2fO9Ll88uTJmjZtmmbOnKktW7YoJiZG3bt314kTJ37jlgIAAABFVyp/wHn99dfr+uuv97nMGKMZM2Zo7Nix6t27tyRpwYIFio6O1sKFC/XAAw/8lk0FAAAAiqxU9oznZ+/evTp48KB69Ohhz3O5XOrcubM2bdqUZ77MzEwdP37cKwEAAABOKnPB+MGDByVJ0dHRXvOjo6PtZb5MnDhR4eHhdqpZs2aJthMAAAC4lDIXjHtYluU1bYzJNS+70aNHKz093U4HDhwo6SYCAAAA+SqVz4znJyYmRtLFHvJq1arZ8w8dOpSrtzw7l8sll8tV4u0DAAAACqrM9YzXrl1bMTExWrVqlT3v7NmzWr9+vTp06OBgywAAAIDCKZU94ydPntR3331nT+/du1fbt29XVFSUatWqpZSUFE2YMEEJCQlKSEjQhAkTFBISor59+zrYagAAAKBwSmUw/tlnn6lLly729COPPCJJGjBggObPn6/HH39cp0+f1pAhQ3T06FG1a9dOK1euVFhYmFNNBgAAAAqtVAbjSUlJMsbkudyyLKWmpio1NfW3a1QZ0+qxV+3/b53S38GWACis0nD9loY2OM2zD36v24/8cY2guJS5Z8YBAACA8oJgHAAAAHAIwTgAAADgEIJxAAAAwCEE4wAAAIBDCMYBAAAAh5TKoQ1/S1f/8U35u9wMS1QOMezU5WMfAgBQsugZBwAAABxCMA4AAAA4hGAcAAAAcAjBOAAAAOAQgnEAAADAIQTjQCnW6rFXvUY0Kev1FFRR2lPatgFAwXH94veMYBwAAABwCME4AAAA4BCCcQAAAMAhBOMAAACAQwjGAQAAAIcQjAMAAAAOCXC6Ab8H2Ydr2jqlv6NtcKp+4PfEiWu+NNxnssuvPb+X+1FpPSYl0RYnjunv5TwqKPZH2UXPOAAAAOAQgnEAAADAIQTjAAAAgEMIxgEAAACHEIwDAAAADmE0ld+hvH5xXdp++Y+icfoX9b/X8yj7dpdU2SW9PxkRAwB+e/SMAwAAAA4hGAcAAAAcQjAOAAAAOIRgHAAAAHAIwTgAAADgEIJxAAAAwCEMbZiHsjLclpNDkeWstySHtMtr2LjSfnzyUpLD4JU2ZeVaKin5XRe/p/MAJee3Oo9+q2FLnf6MKe/3quz35N/7/bm0oGccAAAAcAjBOAAAAOAQgnEAAADAIQTjAAAAgEMIxgEAAACHMJrK/1eUX1IXdx6nR0YpD0pye5z+1flvdY4WRXnY73nVU5pHWSjofi/N21AUvkaD8EwXtayi5s/ZHpRu3E+cxz7IjZ5xAAAAwCEE4wAAAIBDCMYBAAAAhxCMAwAAAA4hGAcAAAAcQjAOAAAAOIShDQugoEMhFWXIpKIMf1RWhtEqze0s68NO5Wyn08N1FVe5hSm7OPKU5nP0t1DazvfSfN9zYl+VtuPjhJIcvrM4h2Qt7mNV2o59Qa6/4h4m1PP/tU8mF6mssoSecQAAAMAhBOMAAACAQwjGAQAAAIcQjAMAAAAOIRgHAAAAHMJoKoVU2F92/5a/qi7JX4YXZPSRgpaXl5z1FOe+Lu7ROorStpIclacwbblUe0ryHC/K8S1K20oyT1GOaV75S9LlHt+C5CnoNevUaDm+ll3q3Lvc+0lBR2rK6zwqyXMvr/Zkl1/b8spflH2Qs87idLn1FORYFYfLvScXNU9B2pNfnuI8X0vbqDFOoWccAAAAcAjBOAAAAOCQMh2Mz5o1S7Vr11ZwcLBatWqlTz75xOkmAQAAAAVWZoPxt956SykpKRo7dqw+//xzderUSddff73279/vdNMAAACAAimzwfi0adN07733atCgQWrYsKFmzJihmjVravbs2U43DQAAACiQMjmaytmzZ7V161Y98cQTXvN79OihTZs2+cyTmZmpzMxMezo9PV2SdOHs6VzrHj9+XBcyT+f7//KepyD5yVO0PKXh+JKHa6m05SkNx4o8XBflIU9pOL7FnUeSjDE+85UHlimDW/fTTz+pevXq2rhxozp06GDPnzBhghYsWKA9e/bkypOamqrx48f/ls0EAABAMThw4IBq1KjhdDNKRJl9TEWSLMvymjbG5JrnMXr0aKWnp9vp6NGj2r59u6SLBzg9PV0HDhywpwvyf/L8dnnKSjvJQ57SnqestJM85CntecpKO8t6nv379+vAgQOKjY1VeVUmH1OpXLmy/P39dfDgQa/5hw4dUnR0tM88LpdLLpfLa56f38W/RSpWrKiKFSva8wv6f/L8dnnKSjvJQ57SnqestJM85CntecpKO8t6nvDwcK/p8qhM9owHBQWpVatWWrVqldf8VatWeT22AgAAAJRmZbJnXJIeeeQR9evXT61bt1b79u310ksvaf/+/XrwwQedbhoAAABQIGU2GL/jjjt0+PBhPf3000pLS1NiYqKWL1+uuLi4Apfhcrk0btw4+/GVnNMF+T95frs8ZaWd5CFPac9TVtpJHvKU9jxlpZ3lIU95ViZHUwEAAADKgzL5zDgAAABQHhCMAwAAAA4hGAcAAAAcUqaD8dTUVDVv3tznsqSkJLnd7jzXN8bo/vvvV0REhCzLUkhIiD3Pz89PlmXZLwXyJT4+XjNmzPAq07IsLV26VJK0bt06WZalWbNmKTQ0VJZl6dixY5Kk5557TpZlea2/b9++XHUOHDhQlmVp586dsixLy5cv91onNTVVQUFBmjFjhs82esps0KCBwsLC8t2miIgIVa9e3S43PDxclmWpR48e9j7ytNXXfvBsT69evZScnOy13JN34MCBXsssy1L9+vVVr149r/0xf/58RURE2McjKipKlmXp5ZdflmVZCgwM1IwZM3TvvffKsix7efv27e1yWrVqZW+Lp3zP/ve02bOPW7duLcuy9Mknn3i1zbIs3XvvvfY8T7ssy9Lw4cMVERFhH4O2bdt6bVvOerK74oorZFmWqlevbm+z53zJvp89x98z7et897TRs6xGjRqyLEv16tVTSkqKPd9zLliWpQcffDDP60aSbrvtNnvd0aNHe217TtnLzd7O0NBQpaSk2NMxMTFe8/KTlJSklJQUxcfHq2/fvj7Pvez1du7cOd82Zt9Xvs5hX/nmz58vy7J000032fMyMjLsOi3L0htvvKHQ0FA1adJETzzxhD2/atWqmjFjht3G2NhY+zzwbJuH5xzJfv1nP2+CgoK8zk3PNqSmpio6Otprm+Lj49W/f397n1SsWNE+732dz772i6/70MaNG9WkSRP5+fnJ7XYrJSVFf/jDH+R2uxUYGGif9y+99JJq1qwpPz8/u/3Zz8+c+z8lJUWWZemuu+7Sli1b7Da6XC4FBATIsiw988wz9jZ4rod27dpJkn3f6dGjh12mr/ZL0qJFi+z9mPM+lJSUlKttMTExXvcMzzXRunVr+/jlzJN9Ovs9MXtbPPvNs33Zl11xxRVeP1SbP3++/Pz8dN111ykqKkotW7a06/CcI577hqednu3P/lmRc5+kpqba9Tdp0kSSdN1119nlZC8z+/9zHo/4+Hg99dRTuerx7LvsaenSpXrppZcUHBxs31euvPJK+7PW5XJ5XSue68Tzr+e+lvPzxZfs25v9cyE2NlaWZalLly6SlGvfZT+GGRkZqlChgt1ez/Zmb5vnHjF69GjVqVPHazveeOMN1atXzyuWSE5Olr+/v31PznkeeniuN095nnkVKlSwy7Msy/4s8rQ/52dJkyZNcu0/zz7xHKPbbrtNQUFB+e7T7NfcwIEDVblyZft6OHbsWK5rJbv58+d7lZ/zM8yzDwYOHGhvW/bPzOz7KOfxyuvzNT+X+oxwlCmCjRs3Gj8/P3PttdcWe7781pkzZ46RZCpVqmSMMWbcuHGmevXqRpKR5JWnc+fOJigoyPj5+dnLxo0bZ5o1a2aMMea5554zkkzbtm3NoEGD7DIsyzJNmzY1d999tzl37pzPNv7hD38wkkybNm3sfHFxcaZGjRpmypQpxhhjMjMzTVpamklOTrbX8WzXiRMnzL/+9S+zc+dOc+bMGTNgwAB7nZzJz8/P3u6qVauagIAAe1lERESe+Tzbkt9ySaZChQomMjLSVKhQwQQGBpqaNWt65QsODjZXX321XZ6/v7+RZBo1amRq166dZ7kVK1Y0zZo1y7NdnuNSoUIFU61aNXvZkiVLTEZGhlm8eLE974knnjAVKlQwLpfLa78EBgYaScbtdpsWLVoYSeb222830dHR5plnnjHGmDzb4CvVqFGjQOtVqFDBREdH29MBAQHGsizjdrvN8OHDzdVXX+11nCzLMsHBwQUq+9lnnzV33313gdtcmNS5c2dz4MAB89e//vWyyjl69Kh9LRQlv+c6HT58uImIiLDPqYKk+++/3zRr1sz079//srZh69atxhhj0tLSzJAhQ0x8fLy9LCIiwnTp0sU+dp7zzbM8NjbW/v/ChQvNf//7X5/neJUqVbzmtW/f3v5/UFCQff22bt3anv/LL7+YuLg4c8UVV9h1Pfzww6Zfv37m5ptvNu+++669rr+/v4mNjTU1atQwNWvWNG632+ta2rhxo2nfvr0ZPny4PS80NNQEBwebm2++2esYLlmyxBhjzPnz501aWpp97/Pcmzp37myuvPJKM3DgQHP8+HFTqVIl43a7TWxsrLnhhhtMenq6CQwMNFFRUWb8+PHm1KlTZsCAASY4ONjrWnn77bfNgAEDzM0332yOHTtmWrdubdq2bWsqVapkJJl58+aZb775xiQnJ5tu3bqZ7t27G0mmY8eOpmHDhiY2Nta0bNnSuFwuk5CQYCSZ7t27mwEDBpiqVavmOg6ecn2lunXrmpo1a+aaHx8fb+68806veRUqVDCSTExMjOnXr589v0qVKqZJkyZGkunTp4/P+/nnn3/uNS8oKMj+v+c88xxPz/nWt29fExMTk+vc8xzD0NBQ88wzz5i1a9d6XZPt2rXLc3styzKtWrUybdu2zVVmfnkutU5ISIipW7duvut47tXZy3W5XCYuLu6S5We/l/r7+5vq1aubBx980Bw5csR07tzZ3Hfffeb+++83NWvWNEFBQaZy5cr2+k2bNjWDBw82vXr18irTz8/PBAUFmS5dupjOnTt7bWfz5s3NkCFDcrW5JFJoaKh9HcbFxZnw8HAjKVd7SyLNmDHD7N27157es2ePMcaY2bNnG7fbbSSZCRMmGEkmKirKWJZlgoKCTKVKlcytt95qH3tJ5qGHHjJZWVm5YqWMjAxzxx13mI4dO16yPYGBgcbPz88MGTLEREVFGUmmWbNm9r0q57l+6NAhc+rUKbsuz30lPxkZGV6f82632zRu3NjMmTMn33zS/+6R+Zk3b54JDw+/5Hq+FKln/JVXXtFDDz2kDRs2aP/+/cWaL791pk2bpubNm+vw4cPavHmzJOnXX39VVFSUJOnjjz/2ynPhwgU1bNhQgYGB+vjjj5Wenm4ve+eddxQWFqbdu3dr586dki7+BWiMkdvtVqVKlWSMkTFG58+f92rH559/rsqVK+vzzz+36/7vf/8rY4wCAi6OFhkUFGT3XHncf//92rBhg37++We1aNFCTZo0sf/y9bw5NCwsTLNmzVKLFi3k5+enrKwse+z0u+++W8nJyerevbsk6cSJE5Kkdu3aqVOnTnnud7fbrRo1atjTlmVpzpw5WrBggaKiopSZmalTp07p/PnzOnnypCIiIux2BQQE2D0qgYGBGjx4sCTpyy+/1N69e+0yPW8zlS72Kh0/flw7duzwudyyLD3++ON223799ddc7Y2MjLSnv/rqK2VkZOjcuXN2/ooVK6pFixaSpFtuucXevsGDBys4OFgVKlSw83t6ONxut90TJP3vDV+BgYGSpB9//FGBgYFe23XDDTdIkvz9/e15mZmZiomJkb+/v7p06aJvvvnGbu8LL7ygH3/8Uddee62dx8/PT7GxsUpISJDb7bZ7EuLj4/XJJ58oJibG7oGdOHGi1q5dq+7du9vb1Lx5cz322GOSLg7pGRISIsuy1KZNG7tNNWrUkNvt1tChQyVd/KYjKSlJ0sVrKi0tTUuWLNGPP/6oESNG2Pu5atWqdhtbtmypHTt2qGvXrnaZDRs2VFpamtLS0vTuu+9Kkn0csvP397ePd5s2bRQYGCi3262OHTuqf//+9jnVr18/vfnmmzp79qxeffVVXbhwQTExMYqMjNTf/vY33XPPPapZs6YkqW3btpIuvszLU3d4eLh9Dnh6OBo3bqwqVarY196iRYv0zjvvaOXKlbrpppvUvXt37d+/Xz/88IMqVaokSYqLi9P333+vFi1aaM2aNZo0aZK9LDo6Wh9//LEkyRijkJAQ+3yVpJ49e3rt97xe0WxyDFT17bff2v9v27atPQxr9vtSzjz+/v6qUaOGff1kvy78/Pzk7+/vdY/Jnr9Ro0Z2z3pOWVlZPtvs7++vmJgYe1961vPcq0JDQxUWFqaTJ0/K7XbL399fgYGB+s9//qNz587J7XarYsWKCgkJsduYvf6AgAC7TLfbLbfbLcuydPbsWUkXj2VCQoLCw8PtnsDsTp8+re3bt2vmzJmqU6eOpP9dv9l5eg999dZ5nDp1SpLstnq2/8cff8y1TzIyMiRJBw8e1H/+8x972b333qvdu3crICBAfn5+9n0zKCgoV32ebfFsqyStXbvW/v+kSZPs/b548WI9/fTTsizL61j95S9/UVRUlE6ePKnp06fr+PHjPrctODjY654lXTw3tm7dql27dtnzkpOTvc6pNm3a2Merd+/euvXWWxUZGWm3vVatWva2XHvttVqwYIHcbrf27dtnlxMREaHIyEgFBQXZ99vs94z+/fsrMTFRvXv31i+//CLLshQcHGznlS4ev+TkZF155ZWqVq2anXfZsmV65ZVX9MEHH2jIkCH2vB07dmjBggX65ptvNHv2bHv9gIAABQQE6NNPP7W3a8GCBZo+fbouXLigjRs36sCBA17fSCQmJmrRokX2sbAsS7Vq1VJkZKSio6MVGRmp8PBw+34h/e8cbNCggf2NfKdOnXTPPffkOjZt2rRRQECA/P39dfr0afvc8uwny7Lse0zlypUlXfys8lzvO3bs0Pbt2xUeHi6Xy6X33ntPkvTiiy/qlltuyVVf37599e9//zvX/OrVq+urr76y2+75vOnSpYtOnz6typUr23FJenq6AgICdPbsWRlj7NgjKSlJ/v7+9jcDObndbgUHBysqKkppaWl69NFHdcUVVygtLU3t27fPdT+zLEunT5/W0aNH7c9wXzGYJFWpUsXr2vUlZ17PPcszJPbOnTuVnJysBx98UG+99Va+ZZW4wkbvJ0+eNGFhYebrr782d9xxhxk/frzX8vfee8+0atXKuFwuU6lSJXPLLbfY+UJDQ829995r3G638ff3N/Xq1TMvv/yyna9evXpef7leddVV5ty5c+bMmTNmyJAhuf6S8vQ2Zu8xlf7XU5lzfRKJRCKRSCRS2UqhoaE+5w8dOvSS34C7XC5ToUIFu8c/ICDAJCUlmfnz5xvpf98+eb79j4qKMm6329SuXdv+tsKTqlWrZpKSkkxoaKgJCwszLVu2NFu2bLF77rOncePGFTi2LnQwPnfuXNO6dWtjjDEffPCBiY+Pt7+e+PDDD42/v7956qmnzJdffmm2b99unn32WTtfZGSkqVmzphkzZoypXr26WbVqlVm0aJH58MMPjZ+fn70TlixZYjp37mz8/PzMU089Zfr06WN/tedyuUyDBg2MZVklHnAT0JNIJBIpv1TQRz5IpeP4cLyc2/clle677z6v6cjISNO4cWN7ukaNGuajjz6y21OrVi3z5ptvej3GVqdOHfPee++ZRo0aGcuyzKuvvmref/99+3HDefPmmbS0NNOgQQNz9913m6+++sp888035u233zbbt283mZmZZsaMGaZixYomLS3NpKWlmRMnTpRcMN6hQwczY8YMY4wx586dM5UrVzarVq0yxhjTvn17c9ddd/nM53mmd9WqVT7zNW7c2AQHB5vp06fbZYeGhtq93n5+fsblcpmrrrrKnD59Olcw7nnGsrgCaMuyvJ4NlS7+NZX9eb+CpMjISMcviLKW8nvOk/1KIjmbcn4TWRzJ80y2VPaCpeHDh3s9q18Wt6E8J89vC/JK2Z9J96SCfAaRvFPDhg2LpRzPs/o5YznPdEJCgtfvKySZVq1aea377LPPmpMnT9rTlStXNqNGjfL6jeGePXu8pmfNmmXHq23atDGjRo0yxhgzefJkI/3vmfGwsDAzf/58n3Hu5TwzXqhg/OuvvzYBAQHm4MGD9ryhQ4ea//u//zPGGON2u80rr7ziM5+n5/vs2bM+83n+Gsle9h133OG1g+Pi4syQIUOMMcbrB1eSCvQjMHq6SSQSiUQqn4k/gspnulQnaM4fbwcEBHj9gS9djBGznx/ZOxUSExPNhQsXjDHGvPPOOyYqKsoEBwd7DRzhCcbHjRtnAgICTNeuXc3EiRPNd999Z8esv1kw/thjj9kb5UmeHusjR46YqKgon8G4J58kOyjPmc+zM3OW7eQJUJhRHkpj8jwfVR5Tcf3S3elzjPTbpLL+h3hZvxeV55TzQ5/j5Vzy1cudMxXkXuDrcyH7c8VOb6cT6VLfFmTvZS5IyivAzv4tk2ed7MfD8//s85YtW+ZVRv369c3u3bvt6aVLl5quXbvaI1cNHjzY7Nixw752H3zwQWOMMZs3bzb+/v6mYcOGpmfPnuabb74xTz/9tJG8R1PZs2ePmTZtmunevbsJCgoyixcvvuxgvMCjqZw/f16vvvqqpk6dqu3bt9tpx44diouL0xtvvKGmTZtq9erVPvONHTvWHsUjZ77ExEQdOXJEVapU0eeff26X7RnjWJJCQ0MVGRmpnj17atGiRbnaFx0drdatWxd0cwrE16+Ds//qujTx9ev9S/3SuCA8vyh3Us4RFaSL50Nx8PyKH+WbyTFKyeXwdV8oaWFhYb95nZfDiX3klEceeSTXvOI834qbZ0Si8iivkY2yy/lZWZDPEs9oOZ7//x75GkUru3r16l2yjJwjK/lSv379XHVec8019rysrCy1bdvWaySWRo0aeZX/zTffaOXKlfbyjh07qnXr1jp48KAs6+L7TZo2bWqPVuOxceNGxcXFqX79+qpcubISEhL0ww8/SLo4Ol/2No4YMUIrV65U7969NW/ePEkXz63s6xVKQaP2JUuWmKCgIHPs2LFcy8aMGWOaN29u1q5da//o8ssvvzQ7d+40/fv3t/MNHDjQ1KxZ0yxZssR8//335q677jJxcXHmT3/6k/1Xbd++fc17771n+vfvbypXrmyPCRkREWEsyzIdO3Y0N954o9dfQZ6/hmvUqFGszzP+Xv8CJpFIJFLBUkF6Y0kkUsGSr2+9Fy5c6DXdpEkTr57xhx9+2Gt5aGioV/xWv359s2TJEvsbqyZNmpg333zT/nFmq1atzJdffmlmzJhh/Pz8TOvWrU3v3r3N888/b6Kiooyfn58ZPHiw+f777829995r1q5da/bt22c2bNhg6tatax5//HFjzMX35EgyH330kfnll1+8xkG/lAIH4zfeeKO54YYbfC7bunWrkS6+SOPdd981zZs3twffj4mJsfOdPn3ajBgxwlSrVs0EBQXZL1zo1KmTadmypalXr569A10ulxk1apT9Q72+fft6ffWX/aUavXr1yvWCjZzJMzh99mRZls+XPpBIpNKZ+PqfRCKRSkcq7IAWRU3/+c9/8l3+l7/8xUiyX5SVMzVr1sxERETYfzhblmWSkpLM7NmzjXTxERxPzJqQkGACAwNNQECAueOOO8z06dNNSEiIqVevngkICDAhISH2C6ZiY2PNsGHDzOnTp+14+MEHH7Qf6SnRoQ3LGs/Yj55ngoqSV/J+62B28+bNM263u8jPCXkMGDDAVKlSxdx9992XVU5+Xn/9dVOpUiWTmZnpc3lezzt169bNPPTQQ5dVt5T/G6wutbygBg0aZK666ip7+sKFC6Z+/frmj3/8Y775xowZYySZn3/+Od/1LrUPjfF9TuS1bz3z582bZ1wul/2GWI/Bgwcb6eJf8jkNGjTI3HTTTXm2Y8OGDUaS+e6777zePpudZ/906tQp1/Ls2/rMM8+YGjVq5Mr/9ddfG0nm22+/NcYYc+rUKRMeHm7efffdXOuePHnShIeH2+8WyO+8yn7d5lV3QY5F9rz5tS0/Od/8VhDXXnutGTp0qD3duXNn8/DDD+ebJy4uzgwfPtz+kfyGDRu8fjDfuXPnS96P4uLi7BGpPHztp1OnTpmwsDAjXXxGM2eeuLg4M3XqVK9r55lnnjGJiYn29oWFhXnlO3/+vAkJCTHvvPOOvU5wcLB97kZHRxs/Pz+TlJTktW9yyrnd2Xmu7wMHDhjp4ttL8yurIOVf6rx4/fXXTWBgoD14QEnKef/KzrPNH330kdd8X8c8p/z2aX48o6AdOXLEvnbzu249y7Kyskz9+vXNpEmTjCR75LScsp9THg0aNLDfZH0pnmOTkZGR6zwv6Dbv37/f+Pn52W/l/a15PvuKcn/y9Ag/++yzua7x7Petgt7DBg0aZOLi4uxjMnHiRNO4ceNcbc3vPM3pmWeesQfcKMw9NLtTp07Z44zfe++9BaozMTExz8+O7Ovlt/y39Pt8+KkUyMjI0Jw5c+w3NW7fvl2//PKLBgwYUCJ17d27VxMnTtQDDzzg8/lyX44cOaKVK1dqzZo1mjlzZrG3qzg899xz6t69uypUqKB//OMfmj9/vv7v//5P33zzjTIzMzVz5kzt3btXffv29Znfs28WLlwoyfez99nXK+w+LKpff/1VGzdu1CuvvOL1Bkbp4tvQtmzZojfeeMN++5okLVmyRKGhoUpISNB3332nhx9+WB07dlTdunXtdX744QetXLlSnTt39to/3bp108aNG+1tnThxohYuXKg+ffrorbfe0pQpUzRs2DCvNh45ckR///vfVbFiRVWvXl0//fSTpk6dqvDwcPXq1Uuff/65vv76a7Vt21bp6el6+umnJUlXX321Fi1alOd5NWvWLHt79+zZozfffNOr7vyOxaxZs9SmTRtVqlRJGzdu1JQpUzR06NBcbSspR48e1aZNm7Ru3Tr7zbkFkZmZqfPnz2v58uW69dZbdeLECT355JPq06eP/Ra8wvK1n7KysnTw4EFNnTpVYWFh9pv0JO9z4+zZs/r73/+uvXv36uabb9aWLVv04osv6oknntCyZcu0bt06+w220sW313reqJqYmKi5c+fqo48+0oULF3Tttdfqu+++07Fjx1S7dm1t3rxZDz/8sM99cODAAa/t9lzfO3fu1CeffKL58+fr0Ucf1W233aaqVavqiy++0NixYwu8j7OXX6VKlXzPi4yMDG3fvl1PPPGEzp8/r+HDhxfpOOQn5/1rwYIFmjVrliRpzZo1OnnypJo0aaK0tDQ9/vjjio+P19VXX13g8n3t07xk/0zas2eP5s6dq88//1xVq1bVPffco6ysLGVlZfm8brN/VowfP17Tpk3Tjz/+aL9F9YorrvBa/+TJk/rqq6/04osv6k9/+pMk6dChQ/rHP/6hPXv22G8BzunVV19VnTp1VL16de3YsUOjRo1S79699f3339vnuTFG33333SW3+dy5c0pLS9MTTzyhK6+8Ui1btizwfi1uR44c0ZNPPlno+5Pnmeq5c+cW6XMp+/m3dOlSzZ8/X263WyNHjtS2bds0b948XX/99fZ60sU3nmY/T/OS/Rjffffdmjp1aqHaJl18PvyHH37Qk08+qTNnzsiyLPtt1L5Mnz5dUVFRmj59unr16pXrc8vX50POzzXHOP3XQEkrrT3jGRkZpmvXriYyMtKEhISYqKgo06ZNm0K3sSA8Q/Fcc801+Q5Cn7P3Ni4uzlSsWLHAvRT5UQn1jN9+++2mSpUqJjg42DRq1Mg8++yzpkOHDqZixYomLCzMtG/f3qxfvz7P/J594+kByus4F3QfGlM8PeOeXtDIyEjz6KOPevVad+7c2bjdbpOSkuJV1oIFC0y9evWMy+Uy1atXNwMGDDC//vqr3f5mzZqZ/fv3+9w/2XvOx40bZyzLMkFBQcblcpmEhATz9NNPm3PnznnVl5ycbGrWrGneeOMNs3fvXiP97+UKxhizbds207JlS1OhQgUTGRlpunXrZnbu3HnJ8yolJcVERUUZSaZixYq56s7vWKSkpJhq1ap5tfvbb7/N1bbCKEzPeHJysqlevboZM2aM/TI0Yy7dMz5v3jy7jdOmTTN+fn6mZcuW5scff/Qq41L3o+y9pL72U/bj9Prrr3v1jGc/NyzLMvHx8Wb9+vVmwIABJigoyPTp08fcfPPN9vbVqlXLrqtSpUqmfv365u233zbJycnGz8/PWJZlOnToYObOnWtPh4WF5do32fdBzu32XN+BgYHG5XKZwMBAU7VqVVOtWjUTExOTZ1l57ePs5fs6Z7MbN26ckS4+GvXMM88UqI7Cynn/mj17tr1sxYoVpnHjxsbtdpuqVaua5ORks2/fvlxl5Ncz7muf5iX7Z1JwcLD9Lo/Q0FDTrVs3Exsbm+d1m/2ali6O63zdddeZqlWr+lw/+zl1/vx5Y8zFXvj4+Hjzwgsv5NnGSZMmmbi4OONyuUx8fLxJSUkxY8aM8TrPC7rNnuu6fv36ZufOnfnum5LkuaaLcn9q166dkWTatGmT615YkJ7x7OdfeHi48ff3N3369DFTp041kZGR5vbbbzeHDx+21/O0M/t5mpfsx/ijjz4qUs+45xqVLo6ecqlvuD1jnfv5+fn83PL1+ZDzc80pljGl+GffAAAAQDlW4KENAQAAABQvgnEAAADAIQTjAAAAgEMIxgEAAACHEIwDAAAADiEYB4AybN26dbIsS8eOHXO6KQCAIiAYB4BicOjQIT3wwAOqVauWXC6XYmJidO2112rz5s3FVkdSUpJSUlK85nXo0EFpaWkKDw8vtnqKauDAgUpOTna6GQBQpvAGTgAoBrfeeqvOnTunBQsWqE6dOvr555+1evVqHTlypETrDQoKUkxMTInWAQAoOfSMA8BlOnbsmDZs2KBJkyapS5cuiouLU9u2bTV69Gj17NlTkpSenq77779fVatWVcWKFXXNNddox44ddhmpqalq3ry5XnvtNcXHxys8PFx33nmn/cr6gQMHav369Xr++edlWZYsy9K+fftyPaYyf/58RURE6MMPP1SDBg0UEhKi2267TadOndKCBQsUHx+vyMhIPfTQQ7pw4YJd/9mzZ/X444+revXqqlChgtq1a6d169bZyz3l/vOf/1TDhg0VGhqq6667TmlpaXb7FyxYoPfee89uX/b8AADfCMYB4DKFhoYqNDRUS5cuVWZmZq7lxhj17NlTBw8e1PLly7V161a1bNlSXbt29eo5/89//qOlS5fqww8/1Icffqj169frz3/+syTp+eefV/v27XXfffcpLS1NaWlpqlmzps/2ZGRk6IUXXtCiRYu0YsUKrVu3Tr1799by5cu1fPlyvfbaa3rppZf097//3c5zzz33aOPGjVq0aJF27typ22+/Xdddd52+/fZbr3Kfe+45vfbaa/r444+1f/9+jRw5UpI0cuRI9enTxw7Q09LS1KFDh2LZvwBQnhGMA8BlCggI0Pz587VgwQJFRESoY8eOGjNmjHbu3ClJWrt2rb744gu98847at26tRISEvTcc88pIiLCKyDOysrS/PnzlZiYqE6dOqlfv35avXq1JCk8PFxBQUEKCQlRTEyMYmJi5O/v77M9586d0+zZs9WiRQtdffXVuu2227RhwwbNnTtXjRo10o033qguXbpo7dq1ki7+EfDmm2/qnXfeUadOnVS3bl2NHDlSV111lebNm+dV7pw5c9S6dWu1bNlSw4YNs9sXGhoqt9ttPy8fExOjoKCgEtnfAFCe8Mw4ABSDW2+9VT179tQnn3yizZs3a8WKFZo8ebJefvll/fLLLzp58qQqVarklef06dP6z3/+Y0/Hx8crLCzMnq5WrZoOHTpU6LaEhISobt269nR0dLTi4+MVGhrqNc9T9rZt22SMUf369b3KyczM9GpzznKL2j4AwP8QjANAMQkODlb37t3VvXt3PfXUUxo0aJDGjRunIUOGqFq1aj6foY6IiLD/HxgY6LXMsixlZWUVuh2+ysmv7KysLPn7+2vr1q25etuzB/C+yjDGFLp9AID/IRgHgBLSqFEjLV26VC1bttTBgwcVEBCg+Pj4IpcXFBTk9aPL4tKiRQtduHBBhw4dUqdOnYpcTkm1DwDKM54ZB4DLdPjwYV1zzTV6/fXXtXPnTu3du1fvvPOOJk+erJtvvlndunVT+/btlZycrH/+85/at2+fNm3apD/+8Y/67LPPClxPfHy8/vWvf2nfvn369ddfi9Rr7kv9+vV11113qX///lq8eLH27t2rLVu2aNKkSVq+fHmh2rdz507t2bNHv/76q86dO1cs7QOA8oxgHAAuU2hoqNq1a6fp06fr6quvVmJiop588kndd999mjlzpizL0vLly3X11VfrD3/4g+rXr68777xT+/btU3R0dIHrGTlypPz9/dWoUSNVqVJF+/fvL7ZtmDdvnvr3769HH31UDRo0UK9evfSvf/0rzxFbfLnvvvvUoEEDtW7dWlWqVNHGjRuLrX0AUF5Zhgf+AAAAAEfQMw4AAAA4hGAcAAAAcAjBOAAAAOAQgnEAAADAIQTjAAAAgEMIxgEAAACHEIwDAAAADiEYBwAAABxCMA4AAAA4hGAcAAAAcAjBOAAAAOCQ/wfHkCRzXu8e0QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['label_cat'] = df['Sentiment'].astype('category')\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(x='label_cat', data=df)\n",
    "plt.title(\"Distribution of Sentiment Labels\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes which were less than 2 were resampleed to 5. This was done to balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = df.copy()\n",
    "for rare_class in rare_classes:\n",
    "    rare_samples = df[df['Sentiment'] == rare_class]\n",
    "    duplicated_samples = resample(rare_samples, replace=True, n_samples=5, random_state=42)  # Duplicate the sample\n",
    "    balanced_df = pd.concat([balanced_df, duplicated_samples], ignore_index=True)\n",
    "df = balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['label_cat'] = df['Sentiment'].astype('category')\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(x='label_cat', data=df)\n",
    "plt.title(\"Distribution of Sentiment Labels\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization\n",
    "\n",
    "Lemmatization is the process of converting a word to its base form. It is similar to stemming, but it is more accurate as it converts the word into a meaningful base form. We used the `WordNetLemmatizer` from the `nltk.stem` module to lemmatize the text data.\n",
    "\n",
    "This is done as part of Data Preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unnecessary URLs, emojis and special characters were removed from the text data.\n",
    "- Only alphabets were retained in the text data.\n",
    "- Tokenization was performed to split the text data into words.\n",
    "- Stopwords were removed from the text data.\n",
    "- Lemmatization was performed to convert words into their base form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+', '', text) \n",
    "    text = emoji.replace_emoji(text, replace='')  \n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  \n",
    "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)  \n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  \n",
    "    tokens = word_tokenize(text)  \n",
    "    tokens = [word for word in tokens if word not in stop_words]  \n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         enjoying beautiful day park\n",
       "1            traffic terrible morning\n",
       "2            finished amazing workout\n",
       "3    excited upcoming weekend getaway\n",
       "4    trying new recipe dinner tonight\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df.copy()\n",
    "df1['clean_text'] = df1['Text'].apply(preprocess_text)\n",
    "(df1['clean_text'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All the classes/sentiments were gives a numerical value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping:\n",
      "{0: 'Acceptance', 1: 'Accomplishment', 2: 'Admiration', 3: 'Adoration', 4: 'Adrenaline', 5: 'Adventure', 6: 'Affection', 7: 'Amazement', 8: 'Ambivalence', 9: 'Amusement', 10: 'Anger', 11: 'Anticipation', 12: 'Anxiety', 13: 'Appreciation', 14: 'Apprehensive', 15: 'Arousal', 16: 'ArtisticBurst', 17: 'Awe', 18: 'Bad', 19: 'Betrayal', 20: 'Bitter', 21: 'Bitterness', 22: 'Bittersweet', 23: 'Blessed', 24: 'Boredom', 25: 'Breakthrough', 26: 'Calmness', 27: 'Captivation', 28: 'Celebration', 29: 'CelestialWonder', 30: 'Challenge', 31: 'Charm', 32: 'Colorful', 33: 'Compassion', 34: 'Compassionate', 35: 'Confidence', 36: 'Confident', 37: 'Confusion', 38: 'Connection', 39: 'Contemplation', 40: 'Contentment', 41: 'Coziness', 42: 'CreativeInspiration', 43: 'Creativity', 44: 'CulinaryAdventure', 45: 'CulinaryOdyssey', 46: 'Curiosity', 47: 'Darkness', 48: 'Dazzle', 49: 'Desolation', 50: 'Despair', 51: 'Desperation', 52: 'Determination', 53: 'Devastated', 54: 'Disappointed', 55: 'Disappointment', 56: 'Disgust', 57: 'Dismissive', 58: 'DreamChaser', 59: 'Ecstasy', 60: 'Elation', 61: 'Elegance', 62: 'Embarrassed', 63: 'Emotion', 64: 'EmotionalStorm', 65: 'Empathetic', 66: 'Empowerment', 67: 'Enchantment', 68: 'Energy', 69: 'Engagement', 70: 'Enjoyment', 71: 'Enthusiasm', 72: 'Envious', 73: 'EnvisioningHistory', 74: 'Envy', 75: 'Euphoria', 76: 'Excitement', 77: 'Exhaustion', 78: 'Exploration', 79: 'Fear', 80: 'Fearful', 81: 'FestiveJoy', 82: 'Free-spirited', 83: 'Freedom', 84: 'Friendship', 85: 'Frustrated', 86: 'Frustration', 87: 'Fulfillment', 88: 'Grandeur', 89: 'Grateful', 90: 'Gratitude', 91: 'Grief', 92: 'Happiness', 93: 'Happy', 94: 'Harmony', 95: 'Hate', 96: 'Heartache', 97: 'Heartbreak', 98: 'Heartwarming', 99: 'Helplessness', 100: 'Hope', 101: 'Hopeful', 102: 'Hypnotic', 103: 'Iconic', 104: 'Imagination', 105: 'Immersion', 106: 'Indifference', 107: 'InnerJourney', 108: 'Inspiration', 109: 'Inspired', 110: 'Intimidation', 111: 'Intrigue', 112: 'Isolation', 113: 'Jealous', 114: 'Jealousy', 115: 'Journey', 116: 'Joy', 117: 'JoyfulReunion', 118: 'JoyinBaking', 119: 'Kind', 120: 'Kindness', 121: 'Loneliness', 122: 'Loss', 123: 'LostLove', 124: 'Love', 125: 'Marvel', 126: 'Melancholy', 127: 'Melodic', 128: 'Mesmerizing', 129: 'Mindfulness', 130: 'Miscalculation', 131: 'Mischievous', 132: 'Motivation', 133: \"Nature'sBeauty\", 134: 'Negative', 135: 'Neutral', 136: 'Nostalgia', 137: 'Numbness', 138: 'Obstacle', 139: \"Ocean'sFreedom\", 140: 'Optimism', 141: 'Overjoyed', 142: 'Overwhelmed', 143: 'Pensive', 144: 'Playful', 145: 'PlayfulJoy', 146: 'Positive', 147: 'Positivity', 148: 'Pressure', 149: 'Pride', 150: 'Proud', 151: 'Radiance', 152: 'Reflection', 153: 'Regret', 154: 'Rejuvenation', 155: 'Relief', 156: 'RenewedEffort', 157: 'Resentment', 158: 'Resilience', 159: 'Reverence', 160: 'Romance', 161: 'Ruins', 162: 'RunwayCreativity', 163: 'Sad', 164: 'Sadness', 165: 'Satisfaction', 166: 'Serenity', 167: 'Shame', 168: 'Solace', 169: 'Solitude', 170: 'Sorrow', 171: 'Spark', 172: 'Success', 173: 'Suffering', 174: 'Surprise', 175: 'Suspense', 176: 'Sympathy', 177: 'Tenderness', 178: 'Thrill', 179: 'ThrillingJourney', 180: 'Touched', 181: 'Tranquility', 182: 'Triumph', 183: 'Vibrancy', 184: 'Whimsy', 185: 'WhispersofthePast', 186: 'WinterMagic', 187: 'Wonder', 188: 'Wonderment', 189: 'Yearning', 190: 'Zest'}\n"
     ]
    }
   ],
   "source": [
    "df1['label_num'] = df1['Sentiment'].astype('category').cat.codes\n",
    "print(\"Label mapping:\")\n",
    "print(dict(enumerate(df1['Sentiment'].astype('category').cat.categories)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Positive\n",
       "1       Negative\n",
       "2       Positive\n",
       "3       Positive\n",
       "4        Neutral\n",
       "          ...   \n",
       "1122    Intrigue\n",
       "1123    Intrigue\n",
       "1124    Intrigue\n",
       "1125    Intrigue\n",
       "1126    Intrigue\n",
       "Name: Sentiment, Length: 1127, dtype: category\n",
       "Categories (191, object): ['Acceptance', 'Accomplishment', 'Admiration', 'Adoration', ..., 'Wonder', 'Wonderment', 'Yearning', 'Zest']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Sentiment'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data into Training and Testing Sets\n",
    "\n",
    "The dataset was split into training and testing sets using the `train_test_split` function from the `sklearn.model_selection` module. The training set was used to train the model, and the testing set was used to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df1, X_test_df1, y_train_df1, y_test_df1 = train_test_split(\n",
    "    df1['clean_text'], df1['label_num'], test_size=0.2, random_state=42, stratify=df1['label_num']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Vectorization using TF-IDF\n",
    "\n",
    "TF-IDF vectorization was performed on the text data using the `TfidfVectorizer` from the `sklearn.feature_extraction.text` module. It converts the text data into numerical features that can be used for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape (TF-IDF): (901, 2057)\n",
      "Testing set shape (TF-IDF): (226, 2057)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf1 = vectorizer.fit_transform(X_train_df1)\n",
    "X_test_tfidf1 = vectorizer.transform(X_test_df1)\n",
    "\n",
    "print(\"Training set shape (TF-IDF):\", X_train_tfidf1.shape)\n",
    "print(\"Testing set shape (TF-IDF):\", X_test_tfidf1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "\n",
    "We have used MLP models for our analysis. The models were trained using the training set and evaluated using the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ap/miniconda3/envs/ap/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential([\n",
    "    Dense(100, activation='relu', input_shape=(2057,)),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(191, activation='softmax') ##! We have used softmax activation function in the output layer because we have multiple classes to predict\n",
    "])\n",
    "model1.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy']) #! We have used Adam optimizer and categorical_crossentropy loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(1024, activation=None, input_shape=(2057,)),  # L1 regularization\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(1024, activation=None),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(512, activation=None),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(191, activation='softmax')\n",
    "]) \n",
    "model2.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential([\n",
    "    Dense(100, activation='relu', input_shape=(2057,)),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(191, activation='softmax')\n",
    "])\n",
    "model3.compile(optimizer=SGD(learning_rate=0.01, momentum=0.9), \n",
    "               loss='sparse_categorical_crossentropy', \n",
    "               metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential([\n",
    "    Dense(1024, activation=None, input_shape=(2057,)),  # L1 regularization\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(1024, activation=None),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(512, activation=None),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(191, activation='softmax')\n",
    "]) \n",
    "model4.compile(optimizer=SGD(learning_rate=0.01, momentum=0.9), \n",
    "               loss='sparse_categorical_crossentropy', \n",
    "               metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicition Function\n",
    "\n",
    "The `pred` function takes model, test data and true test values as input and returns the accuracy score.\n",
    "\n",
    "**NOTE: Since there are 191 classes, we couldn't print out the confusion matrix because of visual cluttering and space constraints.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def pred(model, x_test, y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_test11 = to_categorical(y_test, num_classes=191)\n",
    "    y_test_labels = np.argmax(y_test11, axis=1)\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
    "    # cm = confusion_matrix(y_test_labels, y_pred_labels)\n",
    "    # plt.figure(figsize=(6, 5))\n",
    "    # sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[0, 1, 2], yticklabels=[0, 1, 2])\n",
    "    # plt.xlabel(\"Predicted Label\")\n",
    "    # plt.ylabel(\"True Label\")\n",
    "    # plt.title(\"Confusion Matrix\")\n",
    "    # plt.show()\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot_df1= to_categorical(y_train_df1, num_classes=191) ## One hot encoding of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0295 - loss: 5.2440\n",
      "Epoch 2/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0805 - loss: 5.1650\n",
      "Epoch 3/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0671 - loss: 4.9507\n",
      "Epoch 4/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0477 - loss: 4.5396\n",
      "Epoch 5/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0813 - loss: 4.1646\n",
      "Epoch 6/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1034 - loss: 3.6731\n",
      "Epoch 7/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3613 - loss: 3.1967\n",
      "Epoch 8/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6176 - loss: 2.5821\n",
      "Epoch 9/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7615 - loss: 1.9110\n",
      "Epoch 10/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8115 - loss: 1.4968\n",
      "Epoch 11/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8667 - loss: 1.1008\n",
      "Epoch 12/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9150 - loss: 0.8455\n",
      "Epoch 13/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9481 - loss: 0.6612\n",
      "Epoch 14/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9679 - loss: 0.5014\n",
      "Epoch 15/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9796 - loss: 0.3784\n",
      "Epoch 16/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.2507\n",
      "Epoch 17/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9902 - loss: 0.2310\n",
      "Epoch 18/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.1519\n",
      "Epoch 19/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.1232\n",
      "Epoch 20/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0955\n",
      "Epoch 21/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0854\n",
      "Epoch 22/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0675\n",
      "Epoch 23/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0531\n",
      "Epoch 24/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0447\n",
      "Epoch 25/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0353\n",
      "Epoch 26/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0319\n",
      "Epoch 27/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0316\n",
      "Epoch 28/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0257\n",
      "Epoch 29/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0221\n",
      "Epoch 30/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0203\n",
      "Epoch 31/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0204\n",
      "Epoch 32/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0169\n",
      "Epoch 33/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0153\n",
      "Epoch 34/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0132\n",
      "Epoch 35/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0134\n",
      "Epoch 36/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0123\n",
      "Epoch 37/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0112\n",
      "Epoch 38/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0104\n",
      "Epoch 39/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0104\n",
      "Epoch 40/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0090\n",
      "Epoch 41/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0084\n",
      "Epoch 42/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0081\n",
      "Epoch 43/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0077\n",
      "Epoch 44/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0074\n",
      "Epoch 45/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0071\n",
      "Epoch 46/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0061\n",
      "Epoch 47/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0060\n",
      "Epoch 48/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0057\n",
      "Epoch 49/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0056\n",
      "Epoch 50/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0052\n",
      "Epoch 51/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0049\n",
      "Epoch 52/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0049\n",
      "Epoch 53/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 54/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0043\n",
      "Epoch 55/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0040\n",
      "Epoch 56/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0040\n",
      "Epoch 57/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0039\n",
      "Epoch 58/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 59/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 60/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0032\n",
      "Epoch 61/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0032\n",
      "Epoch 62/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 63/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0030\n",
      "Epoch 64/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0029\n",
      "Epoch 65/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0030\n",
      "Epoch 66/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0027\n",
      "Epoch 67/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 68/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 69/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 70/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 71/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 72/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 73/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 74/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 75/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 76/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 77/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 78/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 79/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 80/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 81/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 82/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 83/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 84/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 85/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 86/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 87/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 88/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 89/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 90/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 91/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 92/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 93/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 94/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 95/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 96/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 97/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 98/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 9.7527e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.7741e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 9.5450e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.3737e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.2730e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 9.4765e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 8.2014e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.2913e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.1507e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.5997e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.8660e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 7.7659e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 7.7369e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 7.5418e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.1640e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 7.0420e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.1442e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.6921e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.8955e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.2051e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.4236e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.0295e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.8563e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.9687e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 5.7569e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 5.6265e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.7049e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.2228e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.2569e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.2880e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 5.0597e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.5291e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.8353e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.3842e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.6637e-04 \n",
      "Epoch 133/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.6063e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.8622e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.2128e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.3404e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.1242e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.0523e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.0385e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.7747e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.8739e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.7295e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.8870e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.7253e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.6090e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.3469e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.3176e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.3600e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.3359e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.2066e-04\n",
      "Epoch 151/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.1088e-04\n",
      "Epoch 152/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.8861e-04\n",
      "Epoch 153/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.0666e-04\n",
      "Epoch 154/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.9296e-04\n",
      "Epoch 155/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.9387e-04\n",
      "Epoch 156/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.7857e-04\n",
      "Epoch 157/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.8763e-04\n",
      "Epoch 158/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.6083e-04\n",
      "Epoch 159/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.5302e-04\n",
      "Epoch 160/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.5438e-04\n",
      "Epoch 161/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.4494e-04\n",
      "Epoch 162/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.4914e-04\n",
      "Epoch 163/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.5510e-04\n",
      "Epoch 164/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.3711e-04\n",
      "Epoch 165/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.2973e-04\n",
      "Epoch 166/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.2752e-04\n",
      "Epoch 167/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.2521e-04 \n",
      "Epoch 168/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.3253e-04\n",
      "Epoch 169/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.3331e-04\n",
      "Epoch 170/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.1093e-04\n",
      "Epoch 171/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.0221e-04\n",
      "Epoch 172/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.1236e-04\n",
      "Epoch 173/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.0820e-04\n",
      "Epoch 174/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.0254e-04\n",
      "Epoch 175/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.0019e-04\n",
      "Epoch 176/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.8330e-04\n",
      "Epoch 177/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.8319e-04\n",
      "Epoch 178/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.8633e-04\n",
      "Epoch 179/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.7949e-04\n",
      "Epoch 180/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.7324e-04\n",
      "Epoch 181/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.6207e-04\n",
      "Epoch 182/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.6994e-04\n",
      "Epoch 183/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.6170e-04\n",
      "Epoch 184/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.6532e-04\n",
      "Epoch 185/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.6541e-04\n",
      "Epoch 186/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.5494e-04\n",
      "Epoch 187/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.4810e-04\n",
      "Epoch 188/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.5428e-04\n",
      "Epoch 189/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.5206e-04\n",
      "Epoch 190/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.4950e-04\n",
      "Epoch 191/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.4599e-04\n",
      "Epoch 192/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.4664e-04\n",
      "Epoch 193/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3304e-04\n",
      "Epoch 194/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.3343e-04\n",
      "Epoch 195/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2720e-04\n",
      "Epoch 196/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.3437e-04\n",
      "Epoch 197/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.2992e-04\n",
      "Epoch 198/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.2457e-04\n",
      "Epoch 199/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.1829e-04\n",
      "Epoch 200/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.2285e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fdc9b303df0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train_tfidf1, y_train_one_hot_df1, epochs=200, batch_size=32) ## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7256637168141593"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(model1,X_test_tfidf1,y_test_df1) ## prediction using the model and accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.0869 - loss: 5.0913\n",
      "Epoch 2/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6370 - loss: 1.9284\n",
      "Epoch 3/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8503 - loss: 0.9767\n",
      "Epoch 4/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9618 - loss: 0.3791\n",
      "Epoch 5/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9864 - loss: 0.1969\n",
      "Epoch 6/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9986 - loss: 0.1015\n",
      "Epoch 7/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0650\n",
      "Epoch 8/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0501\n",
      "Epoch 9/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0343\n",
      "Epoch 10/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9996 - loss: 0.0343\n",
      "Epoch 11/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0289\n",
      "Epoch 12/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9999 - loss: 0.0228\n",
      "Epoch 13/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9998 - loss: 0.0249\n",
      "Epoch 14/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0176\n",
      "Epoch 15/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0211\n",
      "Epoch 16/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0138\n",
      "Epoch 17/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0133\n",
      "Epoch 18/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0110\n",
      "Epoch 19/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0100\n",
      "Epoch 20/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0114\n",
      "Epoch 21/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0081\n",
      "Epoch 22/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0091\n",
      "Epoch 23/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0096\n",
      "Epoch 24/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0063\n",
      "Epoch 25/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0066\n",
      "Epoch 26/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0075\n",
      "Epoch 27/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9999 - loss: 0.0075\n",
      "Epoch 28/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9998 - loss: 0.0081\n",
      "Epoch 29/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9999 - loss: 0.0057\n",
      "Epoch 30/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0062\n",
      "Epoch 31/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0062\n",
      "Epoch 32/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0076\n",
      "Epoch 33/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0059\n",
      "Epoch 34/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0052\n",
      "Epoch 35/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0051\n",
      "Epoch 36/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0049\n",
      "Epoch 37/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9980 - loss: 0.0092\n",
      "Epoch 38/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9981 - loss: 0.0154\n",
      "Epoch 39/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9969 - loss: 0.0273\n",
      "Epoch 40/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0060\n",
      "Epoch 41/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9999 - loss: 0.0068\n",
      "Epoch 42/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0046\n",
      "Epoch 43/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9996 - loss: 0.0037\n",
      "Epoch 44/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9977 - loss: 0.0092\n",
      "Epoch 45/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9958 - loss: 0.0100\n",
      "Epoch 46/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 47/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0048\n",
      "Epoch 48/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0050\n",
      "Epoch 49/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9999 - loss: 0.0036\n",
      "Epoch 50/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0036\n",
      "Epoch 51/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 52/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0039\n",
      "Epoch 53/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9982 - loss: 0.0109\n",
      "Epoch 54/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9987 - loss: 0.0063\n",
      "Epoch 55/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0033\n",
      "Epoch 56/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9997 - loss: 0.0068\n",
      "Epoch 57/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9996 - loss: 0.0049\n",
      "Epoch 58/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9978 - loss: 0.0126\n",
      "Epoch 59/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9921 - loss: 0.0319\n",
      "Epoch 60/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9989 - loss: 0.0135\n",
      "Epoch 61/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9987 - loss: 0.0080\n",
      "Epoch 62/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9966 - loss: 0.0165\n",
      "Epoch 63/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9977 - loss: 0.0128\n",
      "Epoch 64/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0087\n",
      "Epoch 65/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9955 - loss: 0.0185\n",
      "Epoch 66/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9957 - loss: 0.0192\n",
      "Epoch 67/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9969 - loss: 0.0160\n",
      "Epoch 68/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9984 - loss: 0.0069\n",
      "Epoch 69/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0069\n",
      "Epoch 70/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9999 - loss: 0.0058\n",
      "Epoch 71/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0033\n",
      "Epoch 72/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9991 - loss: 0.0050\n",
      "Epoch 73/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 74/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9991 - loss: 0.0035\n",
      "Epoch 75/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0044\n",
      "Epoch 76/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9974 - loss: 0.0088\n",
      "Epoch 77/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9978 - loss: 0.0144\n",
      "Epoch 78/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9984 - loss: 0.0174\n",
      "Epoch 79/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9989 - loss: 0.0122\n",
      "Epoch 80/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9984 - loss: 0.0070\n",
      "Epoch 81/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0063\n",
      "Epoch 82/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 83/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9998 - loss: 0.0045\n",
      "Epoch 84/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 85/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0030\n",
      "Epoch 86/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 87/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 88/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0010    \n",
      "Epoch 89/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 90/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 91/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9995 - loss: 0.0043\n",
      "Epoch 92/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 93/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9983 - loss: 0.0034\n",
      "Epoch 94/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 95/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 96/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9993 - loss: 0.0025\n",
      "Epoch 97/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 98/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 99/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 100/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 101/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.3246e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.6904e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9986 - loss: 0.0033\n",
      "Epoch 104/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9997 - loss: 0.0026 \n",
      "Epoch 105/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9994 - loss: 0.0021\n",
      "Epoch 106/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9989 - loss: 0.0093\n",
      "Epoch 107/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9944 - loss: 0.0157\n",
      "Epoch 108/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9947 - loss: 0.0335\n",
      "Epoch 109/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9989 - loss: 0.0052\n",
      "Epoch 110/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9974 - loss: 0.0080\n",
      "Epoch 111/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9999 - loss: 0.0039\n",
      "Epoch 112/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9963 - loss: 0.0113\n",
      "Epoch 113/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0044\n",
      "Epoch 114/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0049\n",
      "Epoch 115/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0051\n",
      "Epoch 116/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0032\n",
      "Epoch 117/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 118/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 119/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 120/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9991 - loss: 0.0059\n",
      "Epoch 121/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9994 - loss: 0.0029\n",
      "Epoch 122/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0051\n",
      "Epoch 123/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0022\n",
      "Epoch 124/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 125/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9999 - loss: 0.0014\n",
      "Epoch 126/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 127/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 128/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 129/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9989 - loss: 0.0128\n",
      "Epoch 130/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9977 - loss: 0.0079\n",
      "Epoch 131/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0029\n",
      "Epoch 132/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9958 - loss: 0.0086\n",
      "Epoch 133/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 134/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 135/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9987 - loss: 0.0046\n",
      "Epoch 136/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 137/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 138/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9985 - loss: 0.0113\n",
      "Epoch 139/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9981 - loss: 0.0044\n",
      "Epoch 140/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9973 - loss: 0.0103\n",
      "Epoch 141/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9983 - loss: 0.0100\n",
      "Epoch 142/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0058\n",
      "Epoch 143/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0028\n",
      "Epoch 144/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 145/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9999 - loss: 0.0022\n",
      "Epoch 146/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9958 - loss: 0.0152\n",
      "Epoch 147/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9908 - loss: 0.0520\n",
      "Epoch 148/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9953 - loss: 0.0282\n",
      "Epoch 149/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9923 - loss: 0.0585\n",
      "Epoch 150/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9943 - loss: 0.0160\n",
      "Epoch 151/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9952 - loss: 0.0167\n",
      "Epoch 152/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9986 - loss: 0.0109\n",
      "Epoch 153/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9976 - loss: 0.0113\n",
      "Epoch 154/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9995 - loss: 0.0059\n",
      "Epoch 155/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9974 - loss: 0.0071\n",
      "Epoch 156/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9982 - loss: 0.0063\n",
      "Epoch 157/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9994 - loss: 0.0040\n",
      "Epoch 158/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9939 - loss: 0.0163\n",
      "Epoch 159/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 160/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9969 - loss: 0.0054\n",
      "Epoch 161/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 162/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 163/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.1124e-04\n",
      "Epoch 164/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9987 - loss: 0.0033\n",
      "Epoch 165/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 166/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9981 - loss: 0.0037\n",
      "Epoch 167/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 168/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0040\n",
      "Epoch 169/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9999 - loss: 0.0049\n",
      "Epoch 170/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0068\n",
      "Epoch 171/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9966 - loss: 0.0089\n",
      "Epoch 172/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9961 - loss: 0.0336\n",
      "Epoch 173/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9956 - loss: 0.0125\n",
      "Epoch 174/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9984 - loss: 0.0123\n",
      "Epoch 175/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9968 - loss: 0.0132\n",
      "Epoch 176/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9968 - loss: 0.0172\n",
      "Epoch 177/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9987 - loss: 0.0129\n",
      "Epoch 178/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9984 - loss: 0.0091\n",
      "Epoch 179/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9975 - loss: 0.0098\n",
      "Epoch 180/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9976 - loss: 0.0077\n",
      "Epoch 181/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9986 - loss: 0.0054\n",
      "Epoch 182/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0074\n",
      "Epoch 183/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 184/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0026\n",
      "Epoch 185/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 186/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 187/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0022\n",
      "Epoch 188/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 189/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0038\n",
      "Epoch 190/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9997 - loss: 0.0027\n",
      "Epoch 191/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 192/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 193/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 194/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9917 - loss: 0.0213\n",
      "Epoch 195/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 8.7957e-04\n",
      "Epoch 196/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0022\n",
      "Epoch 197/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 198/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 199/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 200/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fdc9c5ce4a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train_tfidf1, y_train_one_hot_df1, epochs=200, batch_size=32) ## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7300884955752213"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(model2,X_test_tfidf1,y_test_df1) ## prediction using the model and accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df1_labels = np.argmax(y_train_one_hot_df1, axis=1) ## Converting the one hot encoded target variable to labels for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0105 - loss: 5.2509    \n",
      "Epoch 2/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0396 - loss: 5.2389\n",
      "Epoch 3/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0425 - loss: 5.2185\n",
      "Epoch 4/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0377 - loss: 5.2059\n",
      "Epoch 5/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0462 - loss: 5.1774\n",
      "Epoch 6/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0425 - loss: 5.1692\n",
      "Epoch 7/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0362 - loss: 5.1508\n",
      "Epoch 8/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0339 - loss: 5.1434   \n",
      "Epoch 9/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0544 - loss: 5.1164\n",
      "Epoch 10/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0484 - loss: 5.0749\n",
      "Epoch 11/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0479 - loss: 5.0680\n",
      "Epoch 12/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0358 - loss: 5.0957 \n",
      "Epoch 13/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0586 - loss: 5.0396\n",
      "Epoch 14/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0490 - loss: 5.0152\n",
      "Epoch 15/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0456 - loss: 5.0408\n",
      "Epoch 16/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0513 - loss: 4.9937\n",
      "Epoch 17/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0474 - loss: 4.9972\n",
      "Epoch 18/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0456 - loss: 4.9908\n",
      "Epoch 19/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0552 - loss: 4.9593\n",
      "Epoch 20/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0508 - loss: 4.9687 \n",
      "Epoch 21/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0434 - loss: 4.9438\n",
      "Epoch 22/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0400 - loss: 4.9565  \n",
      "Epoch 23/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0451 - loss: 4.9120 \n",
      "Epoch 24/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0636 - loss: 4.9356\n",
      "Epoch 25/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0810 - loss: 4.9020\n",
      "Epoch 26/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0381 - loss: 4.9269\n",
      "Epoch 27/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0532 - loss: 4.8877\n",
      "Epoch 28/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0487 - loss: 4.8912\n",
      "Epoch 29/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0315 - loss: 4.9184\n",
      "Epoch 30/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0643 - loss: 4.8913\n",
      "Epoch 31/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0389 - loss: 4.9048\n",
      "Epoch 32/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0399 - loss: 4.8780\n",
      "Epoch 33/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0399 - loss: 4.8634\n",
      "Epoch 34/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0618 - loss: 4.8005\n",
      "Epoch 35/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0594 - loss: 4.8177\n",
      "Epoch 36/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0766 - loss: 4.7779\n",
      "Epoch 37/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0613 - loss: 4.8017\n",
      "Epoch 38/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0589 - loss: 4.8003\n",
      "Epoch 39/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0630 - loss: 4.7526\n",
      "Epoch 40/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0905 - loss: 4.6559\n",
      "Epoch 41/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0780 - loss: 4.6850\n",
      "Epoch 42/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0600 - loss: 4.6751\n",
      "Epoch 43/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0639 - loss: 4.6278\n",
      "Epoch 44/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0779 - loss: 4.6035\n",
      "Epoch 45/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0774 - loss: 4.6189\n",
      "Epoch 46/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0866 - loss: 4.5669\n",
      "Epoch 47/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0901 - loss: 4.4856\n",
      "Epoch 48/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0912 - loss: 4.4736\n",
      "Epoch 49/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0758 - loss: 4.4203   \n",
      "Epoch 50/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0813 - loss: 4.3745\n",
      "Epoch 51/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0851 - loss: 4.3592\n",
      "Epoch 52/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1373 - loss: 4.2657\n",
      "Epoch 53/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1511 - loss: 4.2420\n",
      "Epoch 54/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1741 - loss: 4.1083\n",
      "Epoch 55/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1904 - loss: 4.1025\n",
      "Epoch 56/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2335 - loss: 3.9578\n",
      "Epoch 57/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3083 - loss: 3.9057\n",
      "Epoch 58/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3251 - loss: 3.8465\n",
      "Epoch 59/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3692 - loss: 3.7414\n",
      "Epoch 60/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3951 - loss: 3.6553\n",
      "Epoch 61/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4607 - loss: 3.5693\n",
      "Epoch 62/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5163 - loss: 3.4101\n",
      "Epoch 63/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5370 - loss: 3.2902\n",
      "Epoch 64/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5313 - loss: 3.1602\n",
      "Epoch 65/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5925 - loss: 3.1000\n",
      "Epoch 66/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6189 - loss: 2.8921\n",
      "Epoch 67/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6174 - loss: 2.7943\n",
      "Epoch 68/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6528 - loss: 2.7008\n",
      "Epoch 69/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6274 - loss: 2.5975\n",
      "Epoch 70/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6572 - loss: 2.5266\n",
      "Epoch 71/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6878 - loss: 2.2958\n",
      "Epoch 72/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6783 - loss: 2.2304\n",
      "Epoch 73/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7186 - loss: 2.0491\n",
      "Epoch 74/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7213 - loss: 1.9251\n",
      "Epoch 75/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7235 - loss: 1.8688\n",
      "Epoch 76/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7415 - loss: 1.7152\n",
      "Epoch 77/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7319 - loss: 1.7147\n",
      "Epoch 78/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7544 - loss: 1.5696\n",
      "Epoch 79/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7668 - loss: 1.5857\n",
      "Epoch 80/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7883 - loss: 1.4518\n",
      "Epoch 81/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7509 - loss: 1.4998\n",
      "Epoch 82/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7978 - loss: 1.3694\n",
      "Epoch 83/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8078 - loss: 1.2893\n",
      "Epoch 84/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8053 - loss: 1.2655\n",
      "Epoch 85/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8241 - loss: 1.2087\n",
      "Epoch 86/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8323 - loss: 1.2045\n",
      "Epoch 87/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8353 - loss: 1.1356\n",
      "Epoch 88/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8217 - loss: 1.1271\n",
      "Epoch 89/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8314 - loss: 1.0349\n",
      "Epoch 90/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8433 - loss: 1.0686\n",
      "Epoch 91/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8684 - loss: 0.9100\n",
      "Epoch 92/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8665 - loss: 0.9781\n",
      "Epoch 93/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8721 - loss: 0.8993\n",
      "Epoch 94/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9009 - loss: 0.7721\n",
      "Epoch 95/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8724 - loss: 0.8019\n",
      "Epoch 96/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8834 - loss: 0.7910\n",
      "Epoch 97/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8894 - loss: 0.7832\n",
      "Epoch 98/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8943 - loss: 0.7391\n",
      "Epoch 99/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8973 - loss: 0.7416\n",
      "Epoch 100/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9169 - loss: 0.6839\n",
      "Epoch 101/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9117 - loss: 0.6701\n",
      "Epoch 102/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9161 - loss: 0.6579\n",
      "Epoch 103/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9562 - loss: 0.5856\n",
      "Epoch 104/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9344 - loss: 0.6135\n",
      "Epoch 105/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9588 - loss: 0.5210\n",
      "Epoch 106/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9447 - loss: 0.5943\n",
      "Epoch 107/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9574 - loss: 0.5102\n",
      "Epoch 108/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9576 - loss: 0.4754\n",
      "Epoch 109/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9554 - loss: 0.4942\n",
      "Epoch 110/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9604 - loss: 0.4529\n",
      "Epoch 111/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9718 - loss: 0.4115\n",
      "Epoch 112/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.4522\n",
      "Epoch 113/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9733 - loss: 0.3792\n",
      "Epoch 114/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9777 - loss: 0.3837\n",
      "Epoch 115/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9791 - loss: 0.3718\n",
      "Epoch 116/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9908 - loss: 0.3175\n",
      "Epoch 117/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9717 - loss: 0.3450\n",
      "Epoch 118/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.3257\n",
      "Epoch 119/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9859 - loss: 0.3357\n",
      "Epoch 120/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9901 - loss: 0.3026\n",
      "Epoch 121/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9894 - loss: 0.2775\n",
      "Epoch 122/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9879 - loss: 0.2649\n",
      "Epoch 123/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9936 - loss: 0.2624\n",
      "Epoch 124/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9931 - loss: 0.2331\n",
      "Epoch 125/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9960 - loss: 0.2242\n",
      "Epoch 126/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9943 - loss: 0.2382\n",
      "Epoch 127/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9952 - loss: 0.2082\n",
      "Epoch 128/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9968 - loss: 0.2105\n",
      "Epoch 129/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 0.1938\n",
      "Epoch 130/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9965 - loss: 0.1808\n",
      "Epoch 131/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9950 - loss: 0.1790\n",
      "Epoch 132/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9931 - loss: 0.1914\n",
      "Epoch 133/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9990 - loss: 0.1511\n",
      "Epoch 134/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9980 - loss: 0.1582\n",
      "Epoch 135/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9979 - loss: 0.1459\n",
      "Epoch 136/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.1438\n",
      "Epoch 137/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 0.1401\n",
      "Epoch 138/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.1479\n",
      "Epoch 139/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.1264\n",
      "Epoch 140/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.1269\n",
      "Epoch 141/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.1114\n",
      "Epoch 142/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.1063\n",
      "Epoch 143/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.1003\n",
      "Epoch 144/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0958\n",
      "Epoch 145/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0907\n",
      "Epoch 146/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1034\n",
      "Epoch 147/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.0899\n",
      "Epoch 148/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0865\n",
      "Epoch 149/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0763\n",
      "Epoch 150/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0850\n",
      "Epoch 151/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0801\n",
      "Epoch 152/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0740\n",
      "Epoch 153/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0800\n",
      "Epoch 154/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0742\n",
      "Epoch 155/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0729\n",
      "Epoch 156/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0643\n",
      "Epoch 157/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0624\n",
      "Epoch 158/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0592\n",
      "Epoch 159/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0593\n",
      "Epoch 160/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0572\n",
      "Epoch 161/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0570\n",
      "Epoch 162/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0543\n",
      "Epoch 163/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0530\n",
      "Epoch 164/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0588\n",
      "Epoch 165/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0495\n",
      "Epoch 166/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0451\n",
      "Epoch 167/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0536\n",
      "Epoch 168/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0502\n",
      "Epoch 169/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0516\n",
      "Epoch 170/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0453\n",
      "Epoch 171/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0425\n",
      "Epoch 172/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0455\n",
      "Epoch 173/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0398\n",
      "Epoch 174/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0385\n",
      "Epoch 175/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0395\n",
      "Epoch 176/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0429\n",
      "Epoch 177/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0366\n",
      "Epoch 178/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0398\n",
      "Epoch 179/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0355\n",
      "Epoch 180/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0354\n",
      "Epoch 181/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0354\n",
      "Epoch 182/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0345\n",
      "Epoch 183/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0361\n",
      "Epoch 184/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0368\n",
      "Epoch 185/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0301\n",
      "Epoch 186/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0271\n",
      "Epoch 187/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0285\n",
      "Epoch 188/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0278\n",
      "Epoch 189/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0270\n",
      "Epoch 190/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0313\n",
      "Epoch 191/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0286\n",
      "Epoch 192/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0292\n",
      "Epoch 193/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0277\n",
      "Epoch 194/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0285\n",
      "Epoch 195/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0278\n",
      "Epoch 196/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0262\n",
      "Epoch 197/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0245\n",
      "Epoch 198/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0225\n",
      "Epoch 199/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0234\n",
      "Epoch 200/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fdc9b338820>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train_tfidf1, y_train_df1_labels, epochs=200, batch_size=32) ## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fdc954d1bd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7079646017699115"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(model3,X_test_tfidf1,y_test_df1) ## prediction using the model and accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.0428 - loss: 5.2767\n",
      "Epoch 2/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5808 - loss: 2.4230\n",
      "Epoch 3/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7717 - loss: 1.3747\n",
      "Epoch 4/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8672 - loss: 0.8927\n",
      "Epoch 5/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9668 - loss: 0.5276\n",
      "Epoch 6/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9898 - loss: 0.3401\n",
      "Epoch 7/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9976 - loss: 0.2027\n",
      "Epoch 8/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.1443\n",
      "Epoch 9/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9989 - loss: 0.1027\n",
      "Epoch 10/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.1031\n",
      "Epoch 11/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0729\n",
      "Epoch 12/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0696\n",
      "Epoch 13/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9996 - loss: 0.0551\n",
      "Epoch 14/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0482\n",
      "Epoch 15/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9997 - loss: 0.0542\n",
      "Epoch 16/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0423\n",
      "Epoch 17/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0401\n",
      "Epoch 18/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0363\n",
      "Epoch 19/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0370\n",
      "Epoch 20/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0279\n",
      "Epoch 21/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9984 - loss: 0.0278\n",
      "Epoch 22/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0305\n",
      "Epoch 23/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0272\n",
      "Epoch 24/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0225\n",
      "Epoch 25/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0200\n",
      "Epoch 26/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0303\n",
      "Epoch 27/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0214\n",
      "Epoch 28/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0223\n",
      "Epoch 29/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0199\n",
      "Epoch 30/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0166\n",
      "Epoch 31/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0161\n",
      "Epoch 32/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0136\n",
      "Epoch 33/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0147\n",
      "Epoch 34/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0185\n",
      "Epoch 35/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0140\n",
      "Epoch 36/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0143\n",
      "Epoch 37/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0125\n",
      "Epoch 38/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0121\n",
      "Epoch 39/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0140\n",
      "Epoch 40/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0129\n",
      "Epoch 41/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9988 - loss: 0.0138\n",
      "Epoch 42/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0104\n",
      "Epoch 43/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0104\n",
      "Epoch 44/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0097\n",
      "Epoch 45/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0100\n",
      "Epoch 46/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0096\n",
      "Epoch 47/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0090\n",
      "Epoch 48/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0094\n",
      "Epoch 49/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0097\n",
      "Epoch 50/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0089\n",
      "Epoch 51/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0112\n",
      "Epoch 52/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 0.0108\n",
      "Epoch 53/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0082\n",
      "Epoch 54/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0110\n",
      "Epoch 55/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0098\n",
      "Epoch 56/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0086\n",
      "Epoch 57/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0092\n",
      "Epoch 58/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0067\n",
      "Epoch 59/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0086\n",
      "Epoch 60/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0073\n",
      "Epoch 61/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0079\n",
      "Epoch 62/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0068\n",
      "Epoch 63/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0072\n",
      "Epoch 64/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0057\n",
      "Epoch 65/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0060\n",
      "Epoch 66/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0070\n",
      "Epoch 67/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0063\n",
      "Epoch 68/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0063\n",
      "Epoch 69/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0061\n",
      "Epoch 70/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0049\n",
      "Epoch 71/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0069\n",
      "Epoch 72/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0065\n",
      "Epoch 73/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0057\n",
      "Epoch 74/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0055\n",
      "Epoch 75/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0089\n",
      "Epoch 76/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0057\n",
      "Epoch 77/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0074\n",
      "Epoch 78/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0055\n",
      "Epoch 79/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0051\n",
      "Epoch 80/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0061\n",
      "Epoch 81/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0052\n",
      "Epoch 82/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0047\n",
      "Epoch 83/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0047\n",
      "Epoch 84/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0058\n",
      "Epoch 85/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0055\n",
      "Epoch 86/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0049\n",
      "Epoch 87/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0051\n",
      "Epoch 88/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0060\n",
      "Epoch 89/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0048\n",
      "Epoch 90/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0048\n",
      "Epoch 91/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0065\n",
      "Epoch 92/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0046\n",
      "Epoch 93/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9993 - loss: 0.0062\n",
      "Epoch 94/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0036\n",
      "Epoch 95/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0048\n",
      "Epoch 96/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 97/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 98/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0053\n",
      "Epoch 99/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0036\n",
      "Epoch 100/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0051\n",
      "Epoch 101/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 102/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0043\n",
      "Epoch 103/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 104/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0049\n",
      "Epoch 105/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0040\n",
      "Epoch 106/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0043\n",
      "Epoch 107/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 108/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0032\n",
      "Epoch 109/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 110/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 111/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 112/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9985 - loss: 0.0053\n",
      "Epoch 113/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 114/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0032\n",
      "Epoch 115/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0038\n",
      "Epoch 116/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 0.0046\n",
      "Epoch 117/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 0.0036\n",
      "Epoch 118/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0042\n",
      "Epoch 119/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9985 - loss: 0.0112\n",
      "Epoch 120/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0053\n",
      "Epoch 121/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0053\n",
      "Epoch 122/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 123/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9999 - loss: 0.0042\n",
      "Epoch 124/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 0.0047\n",
      "Epoch 125/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9958 - loss: 0.0097\n",
      "Epoch 126/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9988 - loss: 0.0056\n",
      "Epoch 127/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0095\n",
      "Epoch 128/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9988 - loss: 0.0167\n",
      "Epoch 129/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9990 - loss: 0.0108\n",
      "Epoch 130/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9969 - loss: 0.0179\n",
      "Epoch 131/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9969 - loss: 0.0121\n",
      "Epoch 132/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0051\n",
      "Epoch 133/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0052\n",
      "Epoch 134/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0053\n",
      "Epoch 135/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0048\n",
      "Epoch 136/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0047\n",
      "Epoch 137/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0078\n",
      "Epoch 138/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0050\n",
      "Epoch 139/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 140/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0043\n",
      "Epoch 141/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 142/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 143/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0047\n",
      "Epoch 144/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0038\n",
      "Epoch 145/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0043\n",
      "Epoch 146/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 147/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0113\n",
      "Epoch 148/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 149/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0036\n",
      "Epoch 150/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0039\n",
      "Epoch 151/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0036\n",
      "Epoch 152/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0030\n",
      "Epoch 153/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0030\n",
      "Epoch 154/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0029\n",
      "Epoch 155/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0028\n",
      "Epoch 156/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0033\n",
      "Epoch 157/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 158/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0033\n",
      "Epoch 159/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0056\n",
      "Epoch 160/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0026\n",
      "Epoch 161/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 162/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0030\n",
      "Epoch 163/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0027\n",
      "Epoch 164/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 165/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 166/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 167/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 168/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0032\n",
      "Epoch 169/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 170/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0022\n",
      "Epoch 171/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 172/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 173/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0027\n",
      "Epoch 174/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0027\n",
      "Epoch 175/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 176/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0032\n",
      "Epoch 177/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 178/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0028\n",
      "Epoch 179/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 180/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0022\n",
      "Epoch 181/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 182/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 183/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 184/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0029\n",
      "Epoch 185/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 0.0039\n",
      "Epoch 186/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 187/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0026\n",
      "Epoch 188/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 189/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0027\n",
      "Epoch 190/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 191/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 192/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 193/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 194/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 195/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 0.0047\n",
      "Epoch 196/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0038\n",
      "Epoch 197/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0050\n",
      "Epoch 198/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0029\n",
      "Epoch 199/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0029\n",
      "Epoch 200/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 0.0057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fdc96af6fb0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(X_train_tfidf1, y_train_df1_labels, epochs=200, batch_size=32) ## Fitting the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fdc96eb6050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7300884955752213"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(model4,X_test_tfidf1,y_test_df1)   ## prediction using the model and accuracy calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model\n",
    "\n",
    "The model was saved using the `save` function from the `keras.models` module. The model was saved in the `.keras` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('part2_model1.keras')\n",
    "model2.save('part2_model2.keras')\n",
    "model3.save('part2_model3.keras')\n",
    "model4.save('part2_model4.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
